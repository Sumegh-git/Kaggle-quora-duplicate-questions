{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convnet based Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime, time, json\n",
    "\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Embedding, Dense, Dropout, Reshape, Merge, BatchNormalization, TimeDistributed, Lambda\n",
    "from keras.layers import Conv1D , Flatten, Input\n",
    "from keras.layers.pooling import MaxPooling1D\n",
    "from keras.layers.pooling import GlobalMaxPooling1D\n",
    "\n",
    "\n",
    "\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import Callback, ModelCheckpoint,EarlyStopping\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "\n",
    "from IPython.lib.display import FileLink\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "path = '/home/ubuntu/quora/'\n",
    "data_home = path +\"data/\"\n",
    "\n",
    "Q1_TRAINING_DATA_FILE = data_home+'cache/q1_train.npy'\n",
    "Q2_TRAINING_DATA_FILE = data_home+'cache/q2_train.npy'\n",
    "LABEL_TRAINING_DATA_FILE = data_home+'cache/label_train.npy'\n",
    "WORD_EMBEDDING_MATRIX_FILE = data_home+'cache/word_embedding_matrix.npy'\n",
    "NB_WORDS_DATA_FILE = data_home+'cache/nb_words.json'\n",
    "Q1_TESTING_DATA_FILE = data_home+'q1_test.npy'\n",
    "Q2_TESTING_DATA_FILE = data_home+'q2_test.npy'\n",
    "\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 35\n",
    "EMBEDDING_DIM = 300\n",
    "VALIDATION_SPLIT = 0.1\n",
    "TEST_SPLIT = 0.1\n",
    "RNG_SEED = 13371447\n",
    "NB_EPOCHS = 25\n",
    "\n",
    "\n",
    "re_weight = True # whether to re-weight classes to fit the 17.5% share in test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset, embedding matrix and word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q1_data = np.load(open(Q1_TRAINING_DATA_FILE, 'rb'))\n",
    "q2_data = np.load(open(Q2_TRAINING_DATA_FILE, 'rb'))\n",
    "labels = np.load(open(LABEL_TRAINING_DATA_FILE, 'rb'))\n",
    "word_embedding_matrix = np.load(open(WORD_EMBEDDING_MATRIX_FILE, 'rb'))\n",
    "with open(NB_WORDS_DATA_FILE, 'r') as f:\n",
    "    nb_words = json.load(f)['nb_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404290, 35), (404290, 35))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_data.shape,q2_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read hand-made features by abhishek "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abhishek_train = pd.read_csv(data_home+\"abhishek_train_features.csv\")\n",
    "abhishek_test = pd.read_csv(data_home+\"abhishek_test_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'question1', u'question2', u'len_q1', u'len_q2', u'diff_len',\n",
       "       u'len_char_q1', u'len_char_q2', u'len_word_q1', u'len_word_q2',\n",
       "       u'common_words', u'fuzz_qratio', u'fuzz_WRatio', u'fuzz_partial_ratio',\n",
       "       u'fuzz_partial_token_set_ratio', u'fuzz_partial_token_sort_ratio',\n",
       "       u'fuzz_token_set_ratio', u'fuzz_token_sort_ratio', u'wmd', u'norm_wmd',\n",
       "       u'cosine_distance', u'cityblock_distance', u'jaccard_distance',\n",
       "       u'canberra_distance', u'euclidean_distance', u'minkowski_distance',\n",
       "       u'braycurtis_distance', u'skew_q1vec', u'skew_q2vec', u'kur_q1vec',\n",
       "       u'kur_q2vec'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abhishek_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>len_q1</th>\n",
       "      <th>len_q2</th>\n",
       "      <th>diff_len</th>\n",
       "      <th>len_char_q1</th>\n",
       "      <th>len_char_q2</th>\n",
       "      <th>len_word_q1</th>\n",
       "      <th>len_word_q2</th>\n",
       "      <th>common_words</th>\n",
       "      <th>...</th>\n",
       "      <th>cityblock_distance</th>\n",
       "      <th>jaccard_distance</th>\n",
       "      <th>canberra_distance</th>\n",
       "      <th>euclidean_distance</th>\n",
       "      <th>minkowski_distance</th>\n",
       "      <th>braycurtis_distance</th>\n",
       "      <th>skew_q1vec</th>\n",
       "      <th>skew_q2vec</th>\n",
       "      <th>kur_q1vec</th>\n",
       "      <th>kur_q2vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>66</td>\n",
       "      <td>57</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>5.081614</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.023324</td>\n",
       "      <td>0.371408</td>\n",
       "      <td>0.168999</td>\n",
       "      <td>0.186557</td>\n",
       "      <td>0.031817</td>\n",
       "      <td>-0.091902</td>\n",
       "      <td>0.050416</td>\n",
       "      <td>0.337301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question1  \\\n",
       "0  What is the step by step guide to invest in sh...   \n",
       "\n",
       "                                           question2  len_q1  len_q2  \\\n",
       "0  What is the step by step guide to invest in sh...      66      57   \n",
       "\n",
       "   diff_len  len_char_q1  len_char_q2  len_word_q1  len_word_q2  common_words  \\\n",
       "0         9           20           20           14           12            10   \n",
       "\n",
       "     ...      cityblock_distance  jaccard_distance  canberra_distance  \\\n",
       "0    ...                5.081614               1.0          94.023324   \n",
       "\n",
       "   euclidean_distance  minkowski_distance  braycurtis_distance  skew_q1vec  \\\n",
       "0            0.371408            0.168999             0.186557    0.031817   \n",
       "\n",
       "   skew_q2vec  kur_q1vec  kur_q2vec  \n",
       "0   -0.091902   0.050416   0.337301  \n",
       "\n",
       "[1 rows x 30 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abhishek_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404290, 2345796)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(abhishek_train),len(abhishek_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q1_features = [u'len_q1', u'len_char_q1', u'len_word_q1', u'skew_q1vec', u'kur_q1vec']\n",
    "q2_features = [u'len_q2', u'len_char_q2', u'len_word_q2', u'skew_q2vec', u'kur_q2vec']\n",
    "diff_features = abhishek_train.columns.difference(q1_features).difference(q2_features).difference(['question1','question2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def get_and_normalize_features(df, feature_list):\n",
    "    \n",
    "    np_version = np.array(df.ix[:,feature_list])\n",
    "    np_version = np.nan_to_num(np_version)\n",
    "    np_version = normalize(np_version ,axis=0,norm='max')\n",
    "    \n",
    "    return np_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# abhishek_np= np.array(abhishek_train.ix[:,2:])\n",
    "# abhishek_np = np.nan_to_num(abhishek_np)\n",
    "# abhishek_np[abhishek_np==0]=1e-5\n",
    "\n",
    "# abhishek_np / abhishek_np.sum(axis=1)[:,np.newaxis]\n",
    "# abhishek_np = normalize(abhishek_np ,axis=0,norm='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q1_features_np = get_and_normalize_features(abhishek_train,q1_features)\n",
    "q2_features_np = get_and_normalize_features(abhishek_train,q2_features)\n",
    "diff_features_np = get_and_normalize_features(abhishek_train,diff_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404290, 5), (404290, 5), (404290, 18))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_features_np.shape,q2_features_np.shape,diff_features_np.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read question frequency features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q_frequency = pd.read_csv(\"data/question_frequency_train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404290, 5), (404290,))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_features_np.shape,np.reshape(q_frequency.q1_freq,-1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q1_features_np = np.append(q1_features_np,q_frequency.q1_freq[:,None],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q2_features_np = np.append(q2_features_np,q_frequency.q2_freq[:,None],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read \"group frequency\" features (NOT GOOD - IGNORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# group_freq_train = pd.read_csv(\"data/training_with_group_freq.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# q1_features_np = np.append(q1_features_np,group_freq_train.q1_group_frequency[:,None],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# q2_features_np = np.append(q2_features_np,group_freq_train.q2_group_frequency[:,None],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read \"same group\" feature (DATA LEAK - IGNORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# same_group_train = pd.read_csv(\"data/same_group_train.csv\",)\n",
    "# diff_features_np = np.append(diff_features_np,same_group_train.same_group[:,None],1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read Nostrov's features \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nostrov = pd.read_csv('data/nestrov_feats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ix_train = np.where(nostrov['id'] >= 0)[0]\n",
    "ix_test = np.where(nostrov['id'] == -1)[0]\n",
    "# ix_is_dup = np.where(nostrov['is_duplicate'] == 1)[0]\n",
    "# ix_not_dup = np.where(nostrov['is_duplicate'] == 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nostrov_diff = nostrov.ix[:,9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'abs_diff_len1_len2', u'log_abs_diff_len1_len2', u'ratio_len1_len2',\n",
       "       u'log_ratio_len1_len2', u'unigram_jaccard', u'unigram_all_jaccard',\n",
       "       u'unigram_all_jaccard_max', u'bigram_jaccard', u'bigram_all_jaccard',\n",
       "       u'bigram_all_jaccard_max', u'trigram_jaccard', u'trigram_all_jaccard',\n",
       "       u'trigram_all_jaccard_max', u'quadgram_jaccard',\n",
       "       u'quadgram_all_jaccard', u'quadgram_all_jaccard_max',\n",
       "       u'quadram_tfidf_cosine', u'quadgram_tfidf_l2_euclidean',\n",
       "       u'quadgram_tfidf_l1_euclidean', u'quadgram_tf_l2_euclidean',\n",
       "       u'm_q1_q2_tf_oof', u'm_vstack_svd_q1_q1_euclidean',\n",
       "       u'm_vstack_svd_q1_q1_cosine', u'm_vstack_svd_mult_q1_q2_oof',\n",
       "       u'm_vstack_svd_absdiff_q1_q2_oof', u'1wl_tfidf_cosine',\n",
       "       u'1wl_tfidf_l2_euclidean', u'1wl_tf_l2_euclidean', u'm_w1l_tfidf_oof'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nostrov_diff.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404290, 29)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nostrov_diff.iloc[ix_train].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diff_features_np = np.hstack((diff_features_np,nostrov_diff.iloc[ix_train].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404290, 47)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_features_np.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition the dataset into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# perm = np.random.permutation(len(abhishek_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.stack((q1_data, q2_data), axis=1)\n",
    "y = labels\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SPLIT, random_state=RNG_SEED)\n",
    "# Q1_train = X_train[:,0]\n",
    "# Q2_train = X_train[:,1]\n",
    "# Q1_test = X_test[:,0]\n",
    "# Q2_test = X_test[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=2019)\n",
    "\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    abhishek_train_train, abhishek_train_valid = abhishek_np[train_index], abhishek_np[test_index]\n",
    "\n",
    "Q1_train = X_train[:,0]\n",
    "Q2_train = X_train[:,1]\n",
    "Q1_test = X_test[:,0]\n",
    "Q2_test = X_test[:,1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(363861, 363861, 363861, 40429, 40429, 40429)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Q1_train),len(Q2_train),len(y_train),len(Q1_test),len(Q1_test),len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make random shuffle dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(2189)\n",
    "\n",
    "perm = np.random.permutation(len(q1_data))\n",
    "idx_train = perm[:int(len(q1_data)*(1-VALIDATION_SPLIT))]\n",
    "idx_val = perm[int(len(q1_data)*(1-VALIDATION_SPLIT)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([298787, 215457, 331096, ...,  74226,  16804, 131445])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404290, 6), (363861, 6), (363861, 47))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_features_np.shape,q2_features_np[idx_train].shape,diff_features_np[idx_train].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## training data\n",
    "\n",
    "## normal word2vec embeddings\n",
    "Q1_train = np.vstack((q1_data[idx_train], q2_data[idx_train]))\n",
    "Q2_train = np.vstack((q2_data[idx_train], q1_data[idx_train]))\n",
    "\n",
    "\n",
    "## hand-crafted features\n",
    "train_features_part1 = np.hstack( (q1_features_np[idx_train] ,q2_features_np[idx_train], diff_features_np[idx_train]))\n",
    "train_features_part2 = np.hstack( (q2_features_np[idx_train] ,q1_features_np[idx_train], diff_features_np[idx_train]))\n",
    "\n",
    "abhishek_train_train = np.concatenate((train_features_part1, train_features_part2))\n",
    "\n",
    "y_train = np.concatenate((labels[idx_train], labels[idx_train]))\n",
    "\n",
    "\n",
    "## validation data\n",
    "Q1_test = np.vstack((q1_data[idx_val], q2_data[idx_val]))\n",
    "Q2_test = np.vstack((q2_data[idx_val], q1_data[idx_val]))\n",
    "\n",
    "valid_features_part1 = np.hstack( (q1_features_np[idx_val] ,q2_features_np[idx_val], diff_features_np[idx_val]))\n",
    "valid_features_part2 = np.hstack( (q2_features_np[idx_val] ,q1_features_np[idx_val], diff_features_np[idx_val]))\n",
    "\n",
    "abhishek_train_valid = np.concatenate((valid_features_part1, valid_features_part2))\n",
    "\n",
    "\n",
    "y_test = np.concatenate((labels[idx_val], labels[idx_val]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# len(Q1_train),len(Q2_train),len(y_train),len(Q1_test),len(Q1_test),len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(727722, 59)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abhishek_train_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "re_weight = True \n",
    "\n",
    "if re_weight:\n",
    "    class_weight = {0: 1.309028344, 1: 0.472001959}\n",
    "else:\n",
    "    class_weight = None\n",
    "    \n",
    "    \n",
    "weight_val = np.ones(len(y_test))\n",
    "if re_weight:\n",
    "    weight_val *= 0.472001959\n",
    "    weight_val[y_test==0] = 1.309028344    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_convs():\n",
    "#v2\n",
    "    graph_in = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "    embedded = Embedding(nb_words + 1, \n",
    "                 EMBEDDING_DIM, \n",
    "                 weights=[word_embedding_matrix], \n",
    "                 input_length=MAX_SEQUENCE_LENGTH, \n",
    "                 trainable=False)(graph_in)\n",
    "    \n",
    "#     normalized_input = BatchNormalization()(embedded)\n",
    "    \n",
    "    convs = []\n",
    "\n",
    "    for fsz in range(2,6):\n",
    "        conv = Conv1D(64, fsz,\n",
    "                      padding = 'valid', activation='relu')(embedded)#\n",
    "        conv = Dropout(0.3)(conv)\n",
    "        conv = BatchNormalization()(conv)        \n",
    "        \n",
    "        pool = MaxPooling1D(pool_size=2)(conv)\n",
    "        flatten = Flatten()(pool)\n",
    "#         pool = GlobalMaxPooling1D()(conv)\n",
    "        convs.append(flatten)\n",
    "\n",
    "    out = concatenate(convs) \n",
    "    graph = Model(inputs=graph_in,outputs=out)\n",
    "\n",
    "    return graph\n",
    "\n",
    "\n",
    "# v1\n",
    "#     graph_in = Input(shape=(MAX_SEQUENCE_LENGTH,EMBEDDING_DIM))\n",
    "#     convs = []\n",
    "\n",
    "#     for fsz in range(3,6):\n",
    "#         conv = Conv1D(256, fsz,strides=1,\n",
    "#                             padding = 'valid', activation='relu')(graph_in)#\n",
    "\n",
    "#         pool = MaxPooling1D(pool_length=2)(conv)\n",
    "#         flatten = Flatten()(pool)\n",
    "#         convs.append(flatten)\n",
    "\n",
    "#     out = Merge(mode='concat')(convs) \n",
    "#     graph = Model(input=graph_in,output=out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from keras.layers import Dense, Dropout, Lambda, merge, BatchNormalization, Activation, Input, Merge\n",
    "\n",
    "def create_input_resnet():\n",
    "    \n",
    "    ## raw word2vecs gone through resnet\n",
    "    input_vec = Input(shape=(MAX_SEQUENCE_LENGTH, ))\n",
    "    \n",
    "    \n",
    "    dense1 = Dense(128)(input_vec)\n",
    "    bn1 = BatchNormalization()(dense1)\n",
    "    relu1 = Activation('relu')(bn1)\n",
    "\n",
    "    dense2 = Dense(128)(relu1)\n",
    "    bn2 = BatchNormalization()(dense2)\n",
    "    res2 = merge([relu1, bn2], mode='sum')\n",
    "    relu2 = Activation('relu')(res2)    \n",
    "\n",
    "    dense3 = Dense(128)(relu2)\n",
    "    bn3 = BatchNormalization()(dense3)\n",
    "    res3 = Merge(mode='sum')([relu2, bn3])\n",
    "    relu3 = Activation('relu')(res3)   \n",
    "\n",
    "    feats = merge([relu3, relu2, relu1], mode='concat')\n",
    "    bn4 = BatchNormalization()(feats)\n",
    "    \n",
    "    \n",
    "    graph = Model(inputs=input_vec,outputs=bn4)\n",
    "\n",
    "    \n",
    "    return graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/qenv/lib/python2.7/site-packages/ipykernel/__main__.py:16: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/ubuntu/anaconda2/envs/qenv/lib/python2.7/site-packages/ipykernel/__main__.py:21: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/ubuntu/anaconda2/envs/qenv/lib/python2.7/site-packages/ipykernel/__main__.py:24: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import concatenate\n",
    "\n",
    "### add computation graph to question 1 embeddings\n",
    "graph = get_convs()\n",
    "\n",
    "q1_input = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "q2_input = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "\n",
    "Q1 = graph(q1_input)\n",
    "Q2 = graph(q2_input)\n",
    "\n",
    "\n",
    "q1q2 = concatenate([Q1, Q2])\n",
    "\n",
    "\n",
    "# q1q2 = BatchNormalization()(q1q2)\n",
    "# q1q2 = Dense(200, activation='relu')(q1q2)\n",
    "# q1q2 = Dropout(0.2)(q1q2)\n",
    "\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(200, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "\n",
    "## Add Abhishek features\n",
    "\n",
    "abhishek_features = Input((59,),name=\"abhishek_features\")\n",
    "# abhishek_features_normalized = BatchNormalization()(abhishek_features)\n",
    "\n",
    "# input resnets\n",
    "resnet = create_input_resnet()\n",
    "Q1_res = resnet(q1_input)\n",
    "Q2_res = resnet(q2_input)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = concatenate([Q1,Q2,Q1_res,Q2_res,abhishek_features])\n",
    "model =Dropout(0.2)(model)\n",
    "\n",
    "model = BatchNormalization()(model)\n",
    "model =Dense(200, activation='relu')(model)\n",
    "\n",
    "model =Dropout(0.2)(model)\n",
    "model =BatchNormalization()(model)\n",
    "model =Dense(200, activation='relu')(model)\n",
    "\n",
    "\n",
    "model =Dropout(0.2)(model)\n",
    "model =BatchNormalization()(model)\n",
    "model =Dense(1, activation='sigmoid')(model)\n",
    "\n",
    "model = Model(inputs=[q1_input,q2_input,abhishek_features],outputs=model)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='nadam', \n",
    "              metrics=['accuracy'])#, 'precision', 'recall', 'fbeta_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model, checkpointing weights with best validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training at 2017-05-11 19:49:39.214206\n",
      "Train on 727722 samples, validate on 80858 samples\n",
      "Epoch 1/50\n",
      "727722/727722 [==============================] - 156s - loss: 0.3305 - acc: 0.7441 - val_loss: 0.2814 - val_acc: 0.7531\n",
      "Epoch 2/50\n",
      "727722/727722 [==============================] - 148s - loss: 0.2725 - acc: 0.7871 - val_loss: 0.2559 - val_acc: 0.7755\n",
      "Epoch 3/50\n",
      "727722/727722 [==============================] - 148s - loss: 0.2527 - acc: 0.8075 - val_loss: 0.2429 - val_acc: 0.8150\n",
      "Epoch 4/50\n",
      "727722/727722 [==============================] - 148s - loss: 0.2390 - acc: 0.8220 - val_loss: 0.2407 - val_acc: 0.8344\n",
      "Epoch 5/50\n",
      "727722/727722 [==============================] - 148s - loss: 0.2283 - acc: 0.8313 - val_loss: 0.2356 - val_acc: 0.8352ss: 0 - ETA: 0s - loss: 0.2283 - acc: 0\n",
      "Epoch 6/50\n",
      "727722/727722 [==============================] - 148s - loss: 0.2183 - acc: 0.8410 - val_loss: 0.2353 - val_acc: 0.8240\n",
      "Epoch 7/50\n",
      "727722/727722 [==============================] - 148s - loss: 0.2097 - acc: 0.8480 - val_loss: 0.2344 - val_acc: 0.8382\n",
      "Epoch 8/50\n",
      "727722/727722 [==============================] - 148s - loss: 0.2029 - acc: 0.8542 - val_loss: 0.2301 - val_acc: 0.8382\n",
      "Epoch 9/50\n",
      "727722/727722 [==============================] - 148s - loss: 0.1958 - acc: 0.8607 - val_loss: 0.2291 - val_acc: 0.8388\n",
      "Epoch 10/50\n",
      "727722/727722 [==============================] - 148s - loss: 0.1900 - acc: 0.8660 - val_loss: 0.2309 - val_acc: 0.8382\n",
      "Epoch 11/50\n",
      "727722/727722 [==============================] - 148s - loss: 0.1841 - acc: 0.8709 - val_loss: 0.2336 - val_acc: 0.8455\n",
      "Epoch 12/50\n",
      "727722/727722 [==============================] - 148s - loss: 0.1787 - acc: 0.8757 - val_loss: 0.2404 - val_acc: 0.8534\n",
      "Epoch 13/50\n",
      "727722/727722 [==============================] - 148s - loss: 0.1740 - acc: 0.8795 - val_loss: 0.2354 - val_acc: 0.8506loss: 0.17\n",
      "Training ended at 2017-05-11 20:22:07.423440\n",
      "Minutes elapsed: 32.470147\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting training at\", datetime.datetime.now())\n",
    "t0 = time.time()\n",
    "\n",
    "MODEL_WEIGHTS_FILE = path+'weights/1d_conv_v2_abhishek_qfreq_nostrov2_res_epoch_{epoch:02d}_val_loss_{val_loss:.4f}.h5'\n",
    "\n",
    "early_stopping =EarlyStopping(monitor='val_loss', patience=3)\n",
    "callbacks = [ModelCheckpoint(MODEL_WEIGHTS_FILE, monitor='val_loss', save_best_only=True),early_stopping]\n",
    "\n",
    "history = model.fit([Q1_train, Q2_train,abhishek_train_train],\n",
    "                    y_train,\n",
    "                    epochs=50,\n",
    "                    batch_size=1024,\n",
    "#                     validation_split=0.2,\n",
    "                    validation_data = ([Q1_test, Q2_test,abhishek_train_valid],y_test,weight_val),\n",
    "                    callbacks=callbacks,\n",
    "                    shuffle=True,\n",
    "                    class_weight=class_weight)\n",
    "\n",
    "\n",
    "t1 = time.time()\n",
    "print(\"Training ended at\", datetime.datetime.now())\n",
    "print(\"Minutes elapsed: %f\" % ((t1 - t0) / 60.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot training and validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFBCAYAAABuEzZyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiHx/wEC2a4v9sZEQQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f649aea83d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = pd.DataFrame({'epoch': [ i + 1 for i in history.epoch ],\n",
    "                    'training': history.history['loss'],\n",
    "                    'validation': history.history['val_loss']})\n",
    "ax = acc.ix[:,:].plot(x='epoch', figsize={5,8}, grid=True)\n",
    "ax.set_ylabel(\"loss\")\n",
    "ax.set_ylim([0.0,1.0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print best validation accuracy and epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "without cleaning: Maximum accuracy at epoch 8 = 0.8227\n",
    "with cleaning: Maximum accuracy at epoch 15 = 0.8268\n",
    "with cleaning and stratified: 0.8275"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Loss at epoch 9 = 0.2291\n"
     ]
    }
   ],
   "source": [
    "max_val_acc, idx = min((val, idx) for (idx, val) in enumerate(history.history['val_loss']))\n",
    "print('Minimum Loss at epoch', '{:d}'.format(idx+1), '=', '{:.4f}'.format(max_val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD the best weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !ls weights/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(path+\"weights/1d_conv_v2_abhishek_qfreq_nostrov2_res_epoch_08_val_loss_0.2291.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model with best validation accuracy on the test partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loss, accuracy = model.evaluate([Q1_test, Q2_test], y_test) #, precision, recall, fbeta_score\n",
    "# print('')\n",
    "# print('loss      = {0:.4f}'.format(loss))\n",
    "# print('accuracy  = {0:.4f}'.format(accuracy))\n",
    "# # print('precision = {0:.4f}'.format(precision))\n",
    "# print('recall    = {0:.4f}'.format(recall))\n",
    "# print('F         = {0:.4f}'.format(fbeta_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.390226398346\n",
      "0.409532141018\n",
      "0.390492689424\n",
      "0.389423437025\n"
     ]
    }
   ],
   "source": [
    "val_preds = model.predict([Q1_test, Q2_test,abhishek_train_valid])\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "print (log_loss(y_test,val_preds))\n",
    "print (log_loss(y_test,np.clip(val_preds,1-0.90,0.90)))\n",
    "print (log_loss(y_test,np.clip(val_preds,1-0.98,0.98)))\n",
    "print (log_loss(y_test,np.clip(val_preds,1-0.99,0.99)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abhishek_test = pd.read_csv(data_home+\"abhishek_test_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q_frequency_test = pd.read_csv(\"data/question_frequency_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# group_freq_test = pd.read_csv(\"data/test_with_group_freq.csv\")\n",
    "del group_freq_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q1_test_data = np.load(open(data_home+\"cache/\"+Q1_TESTING_DATA_FILE, 'rb'))\n",
    "q2_test_data = np.load(open(data_home+\"cache/\"+Q2_TESTING_DATA_FILE, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# del abhishek_np # to avoid messing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# same_group_test = pd.read_csv(\"data/same_group_test.csv\",)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prepare features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q1_features_np = get_and_normalize_features(abhishek_test,q1_features)\n",
    "q2_features_np = get_and_normalize_features(abhishek_test,q2_features)\n",
    "diff_features_np = get_and_normalize_features(abhishek_test,diff_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diff_features_np = np.hstack((diff_features_np,nostrov_diff.iloc[ix_test].values))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q1_features_np = np.append(q1_features_np,q_frequency_test.q1_freq[:,None],1)\n",
    "q2_features_np = np.append(q2_features_np,q_frequency_test.q2_freq[:,None],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data leak, hurt log_loss ignore\n",
    "# q1_features_np = np.append(q1_features_np,group_freq_test.q1_group_frequency[:,None],1)\n",
    "# q2_features_np = np.append(q2_features_np,group_freq_test.q2_group_frequency[:,None],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# diff_features_np = np.append(diff_features_np,same_group_test.same_group[:,None],1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_features_part1 = np.hstack( (q1_features_np ,q2_features_np, diff_features_np))\n",
    "test_features_part2 = np.hstack( (q2_features_np ,q1_features_np, diff_features_np))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50.6 s, sys: 10.2 s, total: 1min\n",
      "Wall time: 4min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "preds = model.predict([q1_test_data,q2_test_data,test_features_part1], batch_size=8192)\n",
    "preds_reverse = model.predict([q2_test_data,q1_test_data,test_features_part2], batch_size=8192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = (preds + preds_reverse)/2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2345796, 1)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "flattend = preds.flatten()\n",
    "clipped = flattend\n",
    "\n",
    "# clip =0.98\n",
    "# clipped = np.clip(flattend,1-clip,clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>test_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002620</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.221141</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_duplicate  test_id\n",
       "0      0.002620        0\n",
       "1      0.221141        1"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(data_home+'test.csv')\n",
    "\n",
    "sub = pd.DataFrame({'test_id': df_test['test_id'], 'is_duplicate': clipped})\n",
    "sub.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_name = \"subm/conv1_v2_maxpool2_abhishek_qfreq_nostrov_res.csv\"\n",
    "\n",
    "sub.to_csv(path+submission_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='subm/conv1_v2_maxpool2_abhishek_qfreq_nostrov_res.csv' target='_blank'>subm/conv1_v2_maxpool2_abhishek_qfreq_nostrov_res.csv</a><br>"
      ],
      "text/plain": [
       "/home/ubuntu/quora/subm/conv1_v2_maxpool2_abhishek_qfreq_nostrov_res.csv"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "FileLink(submission_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setting is_duplicate to 1 for those questions that belong to the same group\n",
    "\n",
    "hurt performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# best_preds is from 1d convs + question frequency magic feature\n",
    "best_preds.ix[(best_preds.same_group > 0) , \"is_duplicate\"] = 0.9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# best_preds.ix[best_preds.same_group > 0].is_duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_duplicate    9.999000e-01\n",
       "test_id         1.061650e+06\n",
       "same_group      1.000000e+00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_preds[best_preds.same_group > 0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_preds.drop(\"same_group\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_preds.to_csv(\"subm/qfreq_and_samegrouptomax_3.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='subm/qfreq_and_samegrouptomax_3.csv' target='_blank'>subm/qfreq_and_samegrouptomax_3.csv</a><br>"
      ],
      "text/plain": [
       "/home/ubuntu/quora/subm/qfreq_and_samegrouptomax_3.csv"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileLink(\"subm/qfreq_and_samegrouptomax_3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exact same questions? \n",
    "setting 1 for these questions wouldn't make a difference in score at all; they seem to be all machine generated .. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_preds[\"same_question\"] = same_group_test.question1 == same_group_test.question2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_duplicate     60\n",
       "test_id          60\n",
       "same_question    60\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_preds[best_preds[\"same_question\"]>0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_duplicate           0.999\n",
       "test_id          1315284.350\n",
       "same_question          1.000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_preds[best_preds[\"same_question\"]>0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>same_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10620</th>\n",
       "      <td>10620</td>\n",
       "      <td>What is the police code?</td>\n",
       "      <td>What is the police code?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37823</th>\n",
       "      <td>37823</td>\n",
       "      <td>How love?</td>\n",
       "      <td>How love?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43119</th>\n",
       "      <td>43119</td>\n",
       "      <td>What is?</td>\n",
       "      <td>What is?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106366</th>\n",
       "      <td>106366</td>\n",
       "      <td>What is the</td>\n",
       "      <td>What is the</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129019</th>\n",
       "      <td>129019</td>\n",
       "      <td>Is good or bad?</td>\n",
       "      <td>Is good or bad?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239355</th>\n",
       "      <td>239355</td>\n",
       "      <td>I universe?</td>\n",
       "      <td>I universe?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276281</th>\n",
       "      <td>276281</td>\n",
       "      <td>What is?</td>\n",
       "      <td>What is?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321797</th>\n",
       "      <td>321797</td>\n",
       "      <td>What training?</td>\n",
       "      <td>What training?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330765</th>\n",
       "      <td>330765</td>\n",
       "      <td>What confidence?</td>\n",
       "      <td>What confidence?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391916</th>\n",
       "      <td>391916</td>\n",
       "      <td>What is the reproduction cycle of?</td>\n",
       "      <td>What is the reproduction cycle of?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548625</th>\n",
       "      <td>548625</td>\n",
       "      <td>What is the meaning of the Spanish word?</td>\n",
       "      <td>What is the meaning of the Spanish word?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586965</th>\n",
       "      <td>586965</td>\n",
       "      <td>What is ask a question on Quora?</td>\n",
       "      <td>What is ask a question on Quora?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633119</th>\n",
       "      <td>633119</td>\n",
       "      <td>What is hedge fund have its back office operat...</td>\n",
       "      <td>What is hedge fund have its back office operat...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649615</th>\n",
       "      <td>649615</td>\n",
       "      <td>How do</td>\n",
       "      <td>How do</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692397</th>\n",
       "      <td>692397</td>\n",
       "      <td>Who designed?</td>\n",
       "      <td>Who designed?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741309</th>\n",
       "      <td>741309</td>\n",
       "      <td>What is the purpose of system call in Linux?</td>\n",
       "      <td>What is the purpose of system call in Linux?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786619</th>\n",
       "      <td>786619</td>\n",
       "      <td>Is online gambling legal in?</td>\n",
       "      <td>Is online gambling legal in?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939135</th>\n",
       "      <td>939135</td>\n",
       "      <td>Does luck exist?</td>\n",
       "      <td>Does luck exist?</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939589</th>\n",
       "      <td>939589</td>\n",
       "      <td>What is the best programming blogs?</td>\n",
       "      <td>What is the best programming blogs?</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004367</th>\n",
       "      <td>1004367</td>\n",
       "      <td>How does work?</td>\n",
       "      <td>How does work?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016082</th>\n",
       "      <td>1016082</td>\n",
       "      <td>What are examples of enzymes?</td>\n",
       "      <td>What are examples of enzymes?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195193</th>\n",
       "      <td>1195193</td>\n",
       "      <td>What are some sentence examples using?</td>\n",
       "      <td>What are some sentence examples using?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222166</th>\n",
       "      <td>1222166</td>\n",
       "      <td>What is boot?</td>\n",
       "      <td>What is boot?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261715</th>\n",
       "      <td>1261715</td>\n",
       "      <td>What is proxy war?</td>\n",
       "      <td>What is proxy war?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303810</th>\n",
       "      <td>1303810</td>\n",
       "      <td>How do going to gym?</td>\n",
       "      <td>How do going to gym?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315160</th>\n",
       "      <td>1315160</td>\n",
       "      <td>What are the elements in your life that make it?</td>\n",
       "      <td>What are the elements in your life that make it?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346464</th>\n",
       "      <td>1346464</td>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371236</th>\n",
       "      <td>1371236</td>\n",
       "      <td>Is vegetarian?</td>\n",
       "      <td>Is vegetarian?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373552</th>\n",
       "      <td>1373552</td>\n",
       "      <td>How do start a blog?</td>\n",
       "      <td>How do start a blog?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403597</th>\n",
       "      <td>1403597</td>\n",
       "      <td>What is?</td>\n",
       "      <td>What is?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451815</th>\n",
       "      <td>1451815</td>\n",
       "      <td>Who designed?</td>\n",
       "      <td>Who designed?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452331</th>\n",
       "      <td>1452331</td>\n",
       "      <td>What is the square root of?</td>\n",
       "      <td>What is the square root of?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1480153</th>\n",
       "      <td>1480153</td>\n",
       "      <td>What is the origin of the name?</td>\n",
       "      <td>What is the origin of the name?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1505229</th>\n",
       "      <td>1505229</td>\n",
       "      <td>What is a element?</td>\n",
       "      <td>What is a element?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533767</th>\n",
       "      <td>1533767</td>\n",
       "      <td>What does the Malayalam word mean?</td>\n",
       "      <td>What does the Malayalam word mean?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574685</th>\n",
       "      <td>1574685</td>\n",
       "      <td>What</td>\n",
       "      <td>What</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651015</th>\n",
       "      <td>1651015</td>\n",
       "      <td>What is your review of?</td>\n",
       "      <td>What is your review of?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660051</th>\n",
       "      <td>1660051</td>\n",
       "      <td>How do I fix?</td>\n",
       "      <td>How do I fix?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678505</th>\n",
       "      <td>1678505</td>\n",
       "      <td>Is kosher?</td>\n",
       "      <td>Is kosher?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696103</th>\n",
       "      <td>1696103</td>\n",
       "      <td>How would you Google Maps?</td>\n",
       "      <td>How would you Google Maps?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797182</th>\n",
       "      <td>1797182</td>\n",
       "      <td>Do girls like guys?</td>\n",
       "      <td>Do girls like guys?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799600</th>\n",
       "      <td>1799600</td>\n",
       "      <td>What</td>\n",
       "      <td>What</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799910</th>\n",
       "      <td>1799910</td>\n",
       "      <td>What spiritual?</td>\n",
       "      <td>What spiritual?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1813728</th>\n",
       "      <td>1813728</td>\n",
       "      <td>What is your review of?</td>\n",
       "      <td>What is your review of?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814036</th>\n",
       "      <td>1814036</td>\n",
       "      <td>How English?</td>\n",
       "      <td>How English?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1945287</th>\n",
       "      <td>1945287</td>\n",
       "      <td>What is?</td>\n",
       "      <td>What is?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975287</th>\n",
       "      <td>1975287</td>\n",
       "      <td>What is the difference between middle school a...</td>\n",
       "      <td>What is the difference between middle school a...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990325</th>\n",
       "      <td>1990325</td>\n",
       "      <td>What is?</td>\n",
       "      <td>What is?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992618</th>\n",
       "      <td>1992618</td>\n",
       "      <td>What is?</td>\n",
       "      <td>What is?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040921</th>\n",
       "      <td>2040921</td>\n",
       "      <td>How India?</td>\n",
       "      <td>How India?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046999</th>\n",
       "      <td>2046999</td>\n",
       "      <td>What is annual revenue?</td>\n",
       "      <td>What is annual revenue?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2055932</th>\n",
       "      <td>2055932</td>\n",
       "      <td>How you've had sex?</td>\n",
       "      <td>How you've had sex?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189277</th>\n",
       "      <td>2189277</td>\n",
       "      <td>What is in cricket?</td>\n",
       "      <td>What is in cricket?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2190544</th>\n",
       "      <td>2190544</td>\n",
       "      <td>What is?</td>\n",
       "      <td>What is?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2209760</th>\n",
       "      <td>2209760</td>\n",
       "      <td>What are</td>\n",
       "      <td>What are</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2237047</th>\n",
       "      <td>2237047</td>\n",
       "      <td>What are the best dating in India?</td>\n",
       "      <td>What are the best dating in India?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2252447</th>\n",
       "      <td>2252447</td>\n",
       "      <td>What radiation?</td>\n",
       "      <td>What radiation?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2266256</th>\n",
       "      <td>2266256</td>\n",
       "      <td>What is?</td>\n",
       "      <td>What is?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2272529</th>\n",
       "      <td>2272529</td>\n",
       "      <td>Is flammable?</td>\n",
       "      <td>Is flammable?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2325946</th>\n",
       "      <td>2325946</td>\n",
       "      <td>How</td>\n",
       "      <td>How</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         test_id                                          question1  \\\n",
       "10620      10620                           What is the police code?   \n",
       "37823      37823                                          How love?   \n",
       "43119      43119                                           What is?   \n",
       "106366    106366                                       What is the    \n",
       "129019    129019                                    Is good or bad?   \n",
       "239355    239355                                        I universe?   \n",
       "276281    276281                                           What is?   \n",
       "321797    321797                                     What training?   \n",
       "330765    330765                                   What confidence?   \n",
       "391916    391916                 What is the reproduction cycle of?   \n",
       "548625    548625           What is the meaning of the Spanish word?   \n",
       "586965    586965                   What is ask a question on Quora?   \n",
       "633119    633119  What is hedge fund have its back office operat...   \n",
       "649615    649615                                            How do    \n",
       "692397    692397                                      Who designed?   \n",
       "741309    741309       What is the purpose of system call in Linux?   \n",
       "786619    786619                       Is online gambling legal in?   \n",
       "939135    939135                                   Does luck exist?   \n",
       "939589    939589                What is the best programming blogs?   \n",
       "1004367  1004367                                     How does work?   \n",
       "1016082  1016082                      What are examples of enzymes?   \n",
       "1195193  1195193             What are some sentence examples using?   \n",
       "1222166  1222166                                      What is boot?   \n",
       "1261715  1261715                                 What is proxy war?   \n",
       "1303810  1303810                               How do going to gym?   \n",
       "1315160  1315160   What are the elements in your life that make it?   \n",
       "1346464  1346464                                                 I    \n",
       "1371236  1371236                                     Is vegetarian?   \n",
       "1373552  1373552                               How do start a blog?   \n",
       "1403597  1403597                                           What is?   \n",
       "1451815  1451815                                      Who designed?   \n",
       "1452331  1452331                        What is the square root of?   \n",
       "1480153  1480153                    What is the origin of the name?   \n",
       "1505229  1505229                                 What is a element?   \n",
       "1533767  1533767                 What does the Malayalam word mean?   \n",
       "1574685  1574685                                              What    \n",
       "1651015  1651015                            What is your review of?   \n",
       "1660051  1660051                                      How do I fix?   \n",
       "1678505  1678505                                         Is kosher?   \n",
       "1696103  1696103                         How would you Google Maps?   \n",
       "1797182  1797182                                Do girls like guys?   \n",
       "1799600  1799600                                              What    \n",
       "1799910  1799910                                    What spiritual?   \n",
       "1813728  1813728                            What is your review of?   \n",
       "1814036  1814036                                       How English?   \n",
       "1945287  1945287                                           What is?   \n",
       "1975287  1975287  What is the difference between middle school a...   \n",
       "1990325  1990325                                           What is?   \n",
       "1992618  1992618                                           What is?   \n",
       "2040921  2040921                                         How India?   \n",
       "2046999  2046999                            What is annual revenue?   \n",
       "2055932  2055932                                How you've had sex?   \n",
       "2189277  2189277                                What is in cricket?   \n",
       "2190544  2190544                                           What is?   \n",
       "2209760  2209760                                          What are    \n",
       "2237047  2237047                 What are the best dating in India?   \n",
       "2252447  2252447                                    What radiation?   \n",
       "2266256  2266256                                           What is?   \n",
       "2272529  2272529                                      Is flammable?   \n",
       "2325946  2325946                                               How    \n",
       "\n",
       "                                                 question2 same_group  \n",
       "10620                             What is the police code?      False  \n",
       "37823                                            How love?      False  \n",
       "43119                                             What is?      False  \n",
       "106366                                        What is the       False  \n",
       "129019                                     Is good or bad?      False  \n",
       "239355                                         I universe?      False  \n",
       "276281                                            What is?      False  \n",
       "321797                                      What training?      False  \n",
       "330765                                    What confidence?      False  \n",
       "391916                  What is the reproduction cycle of?      False  \n",
       "548625            What is the meaning of the Spanish word?      False  \n",
       "586965                    What is ask a question on Quora?      False  \n",
       "633119   What is hedge fund have its back office operat...      False  \n",
       "649615                                             How do       False  \n",
       "692397                                       Who designed?      False  \n",
       "741309        What is the purpose of system call in Linux?      False  \n",
       "786619                        Is online gambling legal in?      False  \n",
       "939135                                    Does luck exist?       True  \n",
       "939589                 What is the best programming blogs?       True  \n",
       "1004367                                     How does work?      False  \n",
       "1016082                      What are examples of enzymes?      False  \n",
       "1195193             What are some sentence examples using?      False  \n",
       "1222166                                      What is boot?      False  \n",
       "1261715                                 What is proxy war?      False  \n",
       "1303810                               How do going to gym?      False  \n",
       "1315160   What are the elements in your life that make it?      False  \n",
       "1346464                                                 I       False  \n",
       "1371236                                     Is vegetarian?      False  \n",
       "1373552                               How do start a blog?      False  \n",
       "1403597                                           What is?      False  \n",
       "1451815                                      Who designed?      False  \n",
       "1452331                        What is the square root of?      False  \n",
       "1480153                    What is the origin of the name?      False  \n",
       "1505229                                 What is a element?      False  \n",
       "1533767                 What does the Malayalam word mean?      False  \n",
       "1574685                                              What       False  \n",
       "1651015                            What is your review of?      False  \n",
       "1660051                                      How do I fix?      False  \n",
       "1678505                                         Is kosher?      False  \n",
       "1696103                         How would you Google Maps?      False  \n",
       "1797182                                Do girls like guys?      False  \n",
       "1799600                                              What       False  \n",
       "1799910                                    What spiritual?      False  \n",
       "1813728                            What is your review of?      False  \n",
       "1814036                                       How English?      False  \n",
       "1945287                                           What is?      False  \n",
       "1975287  What is the difference between middle school a...      False  \n",
       "1990325                                           What is?      False  \n",
       "1992618                                           What is?      False  \n",
       "2040921                                         How India?      False  \n",
       "2046999                            What is annual revenue?      False  \n",
       "2055932                                How you've had sex?      False  \n",
       "2189277                                What is in cricket?      False  \n",
       "2190544                                           What is?      False  \n",
       "2209760                                          What are       False  \n",
       "2237047                 What are the best dating in India?      False  \n",
       "2252447                                    What radiation?      False  \n",
       "2266256                                           What is?      False  \n",
       "2272529                                      Is flammable?      False  \n",
       "2325946                                               How       False  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best_preds[best_preds[\"same_question\"]>0]\n",
    "same_group_test[same_group_test.question1 == same_group_test.question2]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:qenv]",
   "language": "python",
   "name": "conda-env-qenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
