{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import textacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/train_clean_vB.csv', \n",
    "                       dtype={\n",
    "                           'q1_clean_vB': unicode,\n",
    "                           'q2_clean_vB': unicode\n",
    "                       }, encoding='utf-8')\n",
    "\n",
    "\n",
    "\n",
    "df_test = pd.read_csv('data/test_clean_vB.csv', \n",
    "                      dtype={\n",
    "                          'q1_clean_vB': unicode,\n",
    "                          'q2_clean_vB': unicode\n",
    "                      } ,encoding='utf-8')\n",
    "\n",
    "\n",
    "# train = pd.read_csv(\"data/train_clean_vB.csv\",encoding=\"utf-8\")\n",
    "# test = pd.read_csv(\"data/test_clean_vB.csv\",encoding=\"utf-8\")\n",
    "\n",
    "# train.fillna(unicode('empty'),inplace=True)\n",
    "# test.fillna(unicode('empty'),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train.rename(columns={\"q1_clean_vB\":\"question1\", \"q2_clean_vB\":\"question2\"}, inplace=True)\n",
    "df_test.rename(columns={\"q1_clean_vB\":\"question1\", \"q2_clean_vB\":\"question2\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id               int64\n",
      "is_duplicate     int64\n",
      "qid1             int64\n",
      "qid2             int64\n",
      "question1       object\n",
      "question2       object\n",
      "test_id          int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_train['test_id'] = -1\n",
    "df_test['id'] = -1\n",
    "df_test['qid1'] = -1\n",
    "df_test['qid2'] = -1\n",
    "df_test['is_duplicate'] = -1\n",
    "\n",
    "df = pd.concat([df_train, df_test])\n",
    "df['question1'] = df['question1'].fillna('')\n",
    "df['question2'] = df['question2'].fillna('')\n",
    "df['uid'] = np.arange(df.shape[0])\n",
    "df = df.set_index(['uid'])\n",
    "print df.dtypes\n",
    "del(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ix_train = np.where(df['id'] >= 0)[0]\n",
    "ix_test = np.where(df['id'] == -1)[0]\n",
    "ix_is_dup = np.where(df['is_duplicate'] == 1)[0]\n",
    "ix_not_dup = np.where(df['is_duplicate'] == 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_questions = pd.concat((df.question1,df.question2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# df1 = train[['question1']].copy()\n",
    "# df2 = train[['question2']].copy()\n",
    "# df1_test = test[['question1']].copy()\n",
    "# df2_test = test[['question2']].copy()\n",
    "\n",
    "\n",
    "# df2.rename(columns = {'question2':'question1'},inplace=True)\n",
    "# df2_test.rename(columns = {'question2':'question1'},inplace=True)\n",
    "\n",
    "# all_questions = df1.append(df2)\n",
    "# all_questions = all_questions.append(df1_test)\n",
    "# all_questions = all_questions.append(df2_test)\n",
    "\n",
    "# len(all_questions) == len(df1)+len(df2)+len(df1_test)+len(df2_test)\n",
    "# all_questions.shape,all_questions.drop_duplicates().shape\n",
    "# all_questions = all_questions.drop_duplicates()\n",
    "# sample = all_questions.iloc[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 1min 7s, sys: 18.5 s, total: 1h 1min 25s\n",
      "Wall time: 21min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "corpus = textacy.corpus.Corpus(lang=unicode(\"en\"),texts=all_questions.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus.save(\"data/\",name=\"textacy_all_questions_corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus = textacy.Corpus.load('data/', name='textacy_corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# matrix_q1_train = (doc.to_terms_list(ngrams=1, named_entities=True, as_strings=True,\n",
    "#                                  normalize ='lemma',filter_stops =True,filter_punct =True,filter_nums=True,min_freq=1\n",
    "#                                 ) for doc in corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/qenv/lib/python2.7/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by the normalize function.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "doc_term_matrix, id2term = textacy.vsm.doc_term_matrix(\n",
    "    (doc.to_terms_list(ngrams=1, named_entities=True, as_strings=True,\n",
    "                       normalize ='lemma',filter_stops =True,filter_punct =True,filter_nums=True,min_freq=1) \n",
    "     for doc in corpus),\n",
    "    weighting='tf', normalize=True, smooth_idf=True, min_df=50, max_df=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5500172x21801 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 26665690 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# id2term\n",
    "doc_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98527223"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = textacy.tm.TopicModel('nmf', n_topics=100)\n",
    "model.fit(doc_term_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_topic_matrix = model.transform(doc_term_matrix)\n",
    "doc_topic_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('topic', 0, ':', u'good   place')\n",
      "('topic', 1, ':', u'india   scope')\n",
      "('topic', 2, ':', u'quora   answer')\n",
      "('topic', 3, ':', u'difference   main')\n",
      "('topic', 4, ':', u'like   look')\n",
      "('topic', 5, ':', u'people   believe')\n",
      "('topic', 6, ':', u'learn   python')\n",
      "('topic', 7, ':', u'life   purpose')\n",
      "('topic', 8, ':', u'way   easy')\n",
      "('topic', 9, ':', u'know   fact')\n",
      "('topic', 10, ':', u'mean   say')\n",
      "('topic', 11, ':', u'work   home')\n",
      "('topic', 12, ':', u'indian   economy')\n",
      "('topic', 13, ':', u'english   speak')\n",
      "('topic', 14, ':', u'trump   donald')\n",
      "('topic', 15, ':', u'think   worry')\n",
      "('topic', 16, ':', u'time   visitor')\n",
      "('topic', 17, ':', u'movie   review')\n",
      "('topic', 18, ':', u'happen   war')\n",
      "('topic', 19, ':', u'use   us')\n",
      "('topic', 20, ':', u'lose   weight')\n",
      "('topic', 21, ':', u'money   earn')\n",
      "('topic', 22, ':', u'find   sydney')\n",
      "('topic', 23, ':', u'america   japan')\n",
      "('topic', 24, ':', u'year   old')\n",
      "('topic', 25, ':', u'start   preparation')\n",
      "('topic', 26, ':', u'day   go')\n",
      "('topic', 27, ':', u'world   war')\n",
      "('topic', 28, ':', u'stop   porn')\n",
      "('topic', 29, ':', u'book   read')\n",
      "('topic', 30, ':', u'thing   employee')\n",
      "('topic', 31, ':', u'love   fall')\n",
      "('topic', 32, ':', u'example   sentence')\n",
      "('topic', 33, ':', u'job   major')\n",
      "('topic', 34, ':', u'girl   guy')\n",
      "('topic', 35, ':', u'number   get')\n",
      "('topic', 36, ':', u'feel   happy')\n",
      "('topic', 37, ':', u'new   go')\n",
      "('topic', 38, ':', u'facebook   password')\n",
      "('topic', 39, ':', u'cause   death')\n",
      "('topic', 40, ':', u'sex   woman')\n",
      "('topic', 41, ':', u'google   search')\n",
      "('topic', 42, ':', u'question   ask')\n",
      "('topic', 43, ':', u'compare   one')\n",
      "('topic', 44, ':', u'instagram   view')\n",
      "('topic', 45, ':', u'long   relationship')\n",
      "('topic', 46, ':', u'friend   talk')\n",
      "('topic', 47, ':', u'increase   height')\n",
      "('topic', 48, ':', u'change   eye')\n",
      "('topic', 49, ':', u'buy   laptop')\n",
      "('topic', 50, ':', u'note   ban')\n",
      "('topic', 51, ':', u'human   animal')\n",
      "('topic', 52, ':', u'study   hard')\n",
      "('topic', 53, ':', u'game   play')\n",
      "('topic', 54, ':', u'engineering   university')\n",
      "('topic', 55, ':', u'app   mobile')\n",
      "('topic', 56, ':', u'company   big')\n",
      "('topic', 57, ':', u'want   share')\n",
      "('topic', 58, ':', u'month   prepare')\n",
      "('topic', 59, ':', u'language   programming')\n",
      "('topic', 60, ':', u'com   review')\n",
      "('topic', 61, ':', u'hillary   clinton')\n",
      "('topic', 62, ':', u'account   gmail')\n",
      "('topic', 63, ':', u'travel   light')\n",
      "('topic', 64, ':', u'bad   experience')\n",
      "('topic', 65, ':', u'person   bring')\n",
      "('topic', 66, ':', u'improve   skill')\n",
      "('topic', 67, ':', u'system   function')\n",
      "('topic', 68, ':', u'android   apps')\n",
      "('topic', 69, ':', u'live   salary')\n",
      "('topic', 70, ':', u'online   earn')\n",
      "('topic', 71, ':', u'eat   food')\n",
      "('topic', 72, ':', u'word   meaning')\n",
      "('topic', 73, ':', u'real   estate')\n",
      "('topic', 74, ':', u'college   class')\n",
      "('topic', 75, ':', u'car   drive')\n",
      "('topic', 76, ':', u'type   blood')\n",
      "('topic', 77, ':', u'website   traffic')\n",
      "('topic', 78, ':', u'great   history')\n",
      "('topic', 79, ':', u'school   high')\n",
      "('topic', 80, ':', u'country   develop')\n",
      "('topic', 81, ':', u'computer   science')\n",
      "('topic', 82, ':', u'win   election')\n",
      "('topic', 83, ':', u'pakistan   china')\n",
      "('topic', 84, ':', u'song   listen')\n",
      "('topic', 85, ':', u'free   download')\n",
      "('topic', 86, ':', u'exist   god')\n",
      "('topic', 87, ':', u'earth   moon')\n",
      "('topic', 88, ':', u'need   mark')\n",
      "('topic', 89, ':', u'+   c')\n",
      "('topic', 90, ':', u'phone   mobile')\n",
      "('topic', 91, ':', u'possible   pursue')\n",
      "('topic', 92, ':', u'different   food')\n",
      "('topic', 93, ':', u'business   small')\n",
      "('topic', 94, ':', u'die   true')\n",
      "('topic', 95, ':', u'make   interview')\n",
      "('topic', 96, ':', u'chinese   western')\n",
      "('topic', 97, ':', u'drug   alcohol')\n",
      "('topic', 98, ':', u'whatsapp   hack')\n",
      "('topic', 99, ':', u'youtube   video')\n"
     ]
    }
   ],
   "source": [
    "for topic_idx, top_terms in model.top_topic_terms(id2term, top_n=2):\n",
    "    print('topic', topic_idx, ':', '   '.join(top_terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.00000000e+00,   1.01534864e-01,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         3.71057920e-05,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         9.65896971e-03,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   1.25499014e-03,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   8.56415334e-03,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   2.01898483e-01,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "         0.00000000e+00])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transform(doc_term_matrix)[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:qenv]",
   "language": "python",
   "name": "conda-env-qenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
