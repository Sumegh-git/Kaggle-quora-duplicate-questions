{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### original text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_frequenties(train_orig,test_orig):\n",
    "    tic0=timeit.default_timer()\n",
    "    df1 = train_orig[['question1']].copy()\n",
    "    df2 = train_orig[['question2']].copy()\n",
    "    df1_test = test_orig[['question1']].copy()\n",
    "    df2_test = test_orig[['question2']].copy()\n",
    "\n",
    "    df2.rename(columns = {'question2':'question1'},inplace=True)\n",
    "    df2_test.rename(columns = {'question2':'question1'},inplace=True)\n",
    "\n",
    "    train_questions = df1.append(df2)\n",
    "    train_questions = train_questions.append(df1_test)\n",
    "    train_questions = train_questions.append(df2_test)\n",
    "    #train_questions.drop_duplicates(subset = ['qid1'],inplace=True)\n",
    "    train_questions.drop_duplicates(subset = ['question1'],inplace=True)\n",
    "\n",
    "    train_questions.reset_index(inplace=True,drop=True)\n",
    "    questions_dict = pd.Series(train_questions.index.values,index=train_questions.question1.values).to_dict()\n",
    "    train_cp = train_orig.copy()\n",
    "    test_cp = test_orig.copy()\n",
    "    train_cp.drop(['qid1','qid2'],axis=1,inplace=True)\n",
    "\n",
    "    test_cp['is_duplicate'] = -1\n",
    "    test_cp.rename(columns={'test_id':'id'},inplace=True)\n",
    "    comb = pd.concat([train_cp,test_cp])\n",
    "\n",
    "    comb['q1_hash'] = comb['question1'].map(questions_dict)\n",
    "    comb['q2_hash'] = comb['question2'].map(questions_dict)\n",
    "\n",
    "    q1_vc = comb.q1_hash.value_counts().to_dict()\n",
    "    q2_vc = comb.q2_hash.value_counts().to_dict()\n",
    "\n",
    "    def try_apply_dict(x,dict_to_apply):\n",
    "        try:\n",
    "            return dict_to_apply[x]\n",
    "        except KeyError:\n",
    "            return 0\n",
    "    #map to frequency space\n",
    "    comb['q1_freq'] = comb['q1_hash'].map(lambda x: try_apply_dict(x,q1_vc) + try_apply_dict(x,q2_vc))\n",
    "    comb['q2_freq'] = comb['q2_hash'].map(lambda x: try_apply_dict(x,q1_vc) + try_apply_dict(x,q2_vc))\n",
    "\n",
    "    train_comb = comb[comb['is_duplicate'] >= 0][['id','q1_hash','q2_hash','q1_freq','q2_freq','is_duplicate']]\n",
    "    test_comb = comb[comb['is_duplicate'] < 0][['id','q1_hash','q2_hash','q1_freq','q2_freq']]\n",
    "\n",
    "    corr_mat = train_comb.corr()\n",
    "    return train_comb, test_comb, corr_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_orig =  pd.read_csv('data/train.csv', header=0)\n",
    "test_orig =  pd.read_csv('data/test.csv', header=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_comb, test_comb, corr_mat = calculate_frequenties(train_orig,test_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>q1_hash</th>\n",
       "      <th>q2_hash</th>\n",
       "      <th>q1_freq</th>\n",
       "      <th>q2_freq</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.692730</td>\n",
       "      <td>0.286969</td>\n",
       "      <td>-0.001608</td>\n",
       "      <td>-0.000777</td>\n",
       "      <td>-0.008784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q1_hash</th>\n",
       "      <td>0.692730</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.492993</td>\n",
       "      <td>-0.341777</td>\n",
       "      <td>-0.202545</td>\n",
       "      <td>-0.206498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q2_hash</th>\n",
       "      <td>0.286969</td>\n",
       "      <td>0.492993</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.392605</td>\n",
       "      <td>-0.466434</td>\n",
       "      <td>-0.349626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q1_freq</th>\n",
       "      <td>-0.001608</td>\n",
       "      <td>-0.341777</td>\n",
       "      <td>-0.392605</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.494315</td>\n",
       "      <td>0.296621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q2_freq</th>\n",
       "      <td>-0.000777</td>\n",
       "      <td>-0.202545</td>\n",
       "      <td>-0.466434</td>\n",
       "      <td>0.494315</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.198609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_duplicate</th>\n",
       "      <td>-0.008784</td>\n",
       "      <td>-0.206498</td>\n",
       "      <td>-0.349626</td>\n",
       "      <td>0.296621</td>\n",
       "      <td>0.198609</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id   q1_hash   q2_hash   q1_freq   q2_freq  is_duplicate\n",
       "id            1.000000  0.692730  0.286969 -0.001608 -0.000777     -0.008784\n",
       "q1_hash       0.692730  1.000000  0.492993 -0.341777 -0.202545     -0.206498\n",
       "q2_hash       0.286969  0.492993  1.000000 -0.392605 -0.466434     -0.349626\n",
       "q1_freq      -0.001608 -0.341777 -0.392605  1.000000  0.494315      0.296621\n",
       "q2_freq      -0.000777 -0.202545 -0.466434  0.494315  1.000000      0.198609\n",
       "is_duplicate -0.008784 -0.206498 -0.349626  0.296621  0.198609      1.000000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_comb.to_csv(\"data/question_frequency_train.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_comb.to_csv(\"data/question_frequency_test.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaned vA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_clean_A =  pd.read_csv('data/train_clean_vA.csv', header=0)\n",
    "test_clean_A =  pd.read_csv('data/test_clean_vA.csv', header=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_clean_A.rename(columns={'q1_clean_vA':'question1', 'q2_clean_vA':'question2'},inplace=True)\n",
    "test_clean_A.rename(columns={'q1_clean_vA':'question1', 'q2_clean_vA':'question2'},inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404290, 2345796)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_clean_A),len(test_clean_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, _ , corr_mat2 = calculate_frequenties(train_clean_A,test_clean_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>q1_hash</th>\n",
       "      <th>q2_hash</th>\n",
       "      <th>q1_freq</th>\n",
       "      <th>q2_freq</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.690644</td>\n",
       "      <td>0.284510</td>\n",
       "      <td>-0.001176</td>\n",
       "      <td>-0.001258</td>\n",
       "      <td>-0.008784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q1_hash</th>\n",
       "      <td>0.690644</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.491655</td>\n",
       "      <td>-0.213964</td>\n",
       "      <td>-0.147792</td>\n",
       "      <td>-0.206274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q2_hash</th>\n",
       "      <td>0.284510</td>\n",
       "      <td>0.491655</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.242893</td>\n",
       "      <td>-0.340867</td>\n",
       "      <td>-0.347962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q1_freq</th>\n",
       "      <td>-0.001176</td>\n",
       "      <td>-0.213964</td>\n",
       "      <td>-0.242893</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.302562</td>\n",
       "      <td>0.175250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q2_freq</th>\n",
       "      <td>-0.001258</td>\n",
       "      <td>-0.147792</td>\n",
       "      <td>-0.340867</td>\n",
       "      <td>0.302562</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.137030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_duplicate</th>\n",
       "      <td>-0.008784</td>\n",
       "      <td>-0.206274</td>\n",
       "      <td>-0.347962</td>\n",
       "      <td>0.175250</td>\n",
       "      <td>0.137030</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id   q1_hash   q2_hash   q1_freq   q2_freq  is_duplicate\n",
       "id            1.000000  0.690644  0.284510 -0.001176 -0.001258     -0.008784\n",
       "q1_hash       0.690644  1.000000  0.491655 -0.213964 -0.147792     -0.206274\n",
       "q2_hash       0.284510  0.491655  1.000000 -0.242893 -0.340867     -0.347962\n",
       "q1_freq      -0.001176 -0.213964 -0.242893  1.000000  0.302562      0.175250\n",
       "q2_freq      -0.001258 -0.147792 -0.340867  0.302562  1.000000      0.137030\n",
       "is_duplicate -0.008784 -0.206274 -0.347962  0.175250  0.137030      1.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_mat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaned vB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_clean_B=  pd.read_csv('data/train_clean_vB.csv', header=0)\n",
    "test_clean_B =  pd.read_csv('data/test_clean_vB.csv', header=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_clean_B.rename(columns={'q1_clean_vB':'question1', 'q2_clean_vB':'question2'},inplace=True)\n",
    "test_clean_B.rename(columns={'q1_clean_vB':'question1', 'q2_clean_vB':'question2'},inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>q1_hash</th>\n",
       "      <th>q2_hash</th>\n",
       "      <th>q1_freq</th>\n",
       "      <th>q2_freq</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.692021</td>\n",
       "      <td>0.285729</td>\n",
       "      <td>-0.001367</td>\n",
       "      <td>-0.000256</td>\n",
       "      <td>-0.008784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q1_hash</th>\n",
       "      <td>0.692021</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.491649</td>\n",
       "      <td>-0.297582</td>\n",
       "      <td>-0.197499</td>\n",
       "      <td>-0.207086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q2_hash</th>\n",
       "      <td>0.285729</td>\n",
       "      <td>0.491649</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.340953</td>\n",
       "      <td>-0.456914</td>\n",
       "      <td>-0.353699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q1_freq</th>\n",
       "      <td>-0.001367</td>\n",
       "      <td>-0.297582</td>\n",
       "      <td>-0.340953</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.422082</td>\n",
       "      <td>0.257274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q2_freq</th>\n",
       "      <td>-0.000256</td>\n",
       "      <td>-0.197499</td>\n",
       "      <td>-0.456914</td>\n",
       "      <td>0.422082</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.193832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_duplicate</th>\n",
       "      <td>-0.008784</td>\n",
       "      <td>-0.207086</td>\n",
       "      <td>-0.353699</td>\n",
       "      <td>0.257274</td>\n",
       "      <td>0.193832</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id   q1_hash   q2_hash   q1_freq   q2_freq  is_duplicate\n",
       "id            1.000000  0.692021  0.285729 -0.001367 -0.000256     -0.008784\n",
       "q1_hash       0.692021  1.000000  0.491649 -0.297582 -0.197499     -0.207086\n",
       "q2_hash       0.285729  0.491649  1.000000 -0.340953 -0.456914     -0.353699\n",
       "q1_freq      -0.001367 -0.297582 -0.340953  1.000000  0.422082      0.257274\n",
       "q2_freq      -0.000256 -0.197499 -0.456914  0.422082  1.000000      0.193832\n",
       "is_duplicate -0.008784 -0.207086 -0.353699  0.257274  0.193832      1.000000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, _ , corr_mat3 = calculate_frequenties(train_clean_B,test_clean_B)\n",
    "corr_mat3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems the more it's cleaned the less the correlation; probably my cleaning function makes different questions look the same, hence reducing the score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keyword extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.summarization import summarize, keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Will there really be any war between India and Pakistan over the Uri attack? What will be its effects?',\n",
       " 'Will there be a nuclear war between India and Pakistan?')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qid = 100 \n",
    "\n",
    "train_orig.ix[qid].question1, train_orig.ix[qid].question2"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:qenv]",
   "language": "python",
   "name": "conda-env-qenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
