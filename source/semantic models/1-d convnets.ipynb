{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convnet based Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime, time, json\n",
    "\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Embedding, Dense, Dropout, Reshape, Merge, BatchNormalization, TimeDistributed, Lambda\n",
    "from keras.layers import Conv1D , Flatten, Input\n",
    "from keras.layers.pooling import MaxPooling1D\n",
    "from keras.layers.pooling import GlobalMaxPooling1D\n",
    "\n",
    "\n",
    "\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import Callback, ModelCheckpoint,EarlyStopping\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "path = '/home/ubuntu/quora/'\n",
    "data_home = path +\"data/\"\n",
    "\n",
    "Q1_TRAINING_DATA_FILE = data_home+'cache/q1_train.npy'\n",
    "Q2_TRAINING_DATA_FILE = data_home+'cache/q2_train.npy'\n",
    "LABEL_TRAINING_DATA_FILE = data_home+'cache/label_train.npy'\n",
    "WORD_EMBEDDING_MATRIX_FILE = data_home+'cache/word_embedding_matrix.npy'\n",
    "NB_WORDS_DATA_FILE = data_home+'cache/nb_words.json'\n",
    "Q1_TESTING_DATA_FILE = 'q1_test.npy'\n",
    "Q2_TESTING_DATA_FILE = 'q2_test.npy'\n",
    "\n",
    "# Q1_TRAINING_DATA_FILE = data_home+'cache/q1_train_google.npy'\n",
    "# Q2_TRAINING_DATA_FILE = data_home+'cache/q2_train_google.npy'\n",
    "# LABEL_TRAINING_DATA_FILE = data_home+'cache/label_train.npy'\n",
    "# WORD_EMBEDDING_MATRIX_FILE = data_home+'cache/word_embedding_matrix_google.npy'\n",
    "# NB_WORDS_DATA_FILE = data_home+'cache/nb_words_google.json'\n",
    "# Q1_TESTING_DATA_FILE = 'q1_test_google.npy'\n",
    "# Q2_TESTING_DATA_FILE = 'q2_test_google.npy'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 35\n",
    "EMBEDDING_DIM = 300\n",
    "VALIDATION_SPLIT = 0.1\n",
    "TEST_SPLIT = 0.1\n",
    "RNG_SEED = 13371447\n",
    "NB_EPOCHS = 25\n",
    "\n",
    "\n",
    "re_weight = True # whether to re-weight classes to fit the 17.5% share in test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset, embedding matrix and word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# q1_data = np.load(open(Q1_TRAINING_DATA_FILE, 'rb'))\n",
    "# q2_data = np.load(open(Q2_TRAINING_DATA_FILE, 'rb'))\n",
    "# labels = np.load(open(LABEL_TRAINING_DATA_FILE, 'rb'))\n",
    "# word_embedding_matrix = np.load(open(WORD_EMBEDDING_MATRIX_FILE, 'rb'))\n",
    "# with open(NB_WORDS_DATA_FILE, 'r') as f:\n",
    "#     nb_words = json.load(f)['nb_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404290, 35), (404290, 35))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_data.shape,q2_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_1 = np.load(open(Q1_TRAINING_DATA_FILE, 'rb'))\n",
    "data_2 = np.load(open(Q2_TRAINING_DATA_FILE, 'rb'))\n",
    "labels = np.load(open(LABEL_TRAINING_DATA_FILE, 'rb'))\n",
    "word_embedding_matrix = np.load(open(WORD_EMBEDDING_MATRIX_FILE, 'rb'))\n",
    "with open(NB_WORDS_DATA_FILE, 'r') as f:\n",
    "    nb_words = json.load(f)['nb_words']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_data_1 = np.load(open(data_home+\"cache/\"+Q1_TESTING_DATA_FILE, 'rb'))\n",
    "test_data_2 = np.load(open(data_home+\"cache/\"+Q2_TESTING_DATA_FILE, 'rb'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "perm = np.random.permutation(len(data_1))\n",
    "idx_train = perm[:int(len(data_1)*(1-VALIDATION_SPLIT))]\n",
    "idx_val = perm[int(len(data_1)*(1-VALIDATION_SPLIT)):]\n",
    "\n",
    "data_1_train = np.vstack((data_1[idx_train], data_2[idx_train]))\n",
    "data_2_train = np.vstack((data_2[idx_train], data_1[idx_train]))\n",
    "labels_train = np.concatenate((labels[idx_train], labels[idx_train]))\n",
    "\n",
    "data_1_val = np.vstack((data_1[idx_val], data_2[idx_val]))\n",
    "data_2_val = np.vstack((data_2[idx_val], data_1[idx_val]))\n",
    "labels_val = np.concatenate((labels[idx_val], labels[idx_val]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight_val = np.ones(len(labels_val))\n",
    "if re_weight:\n",
    "    weight_val *= 0.472001959\n",
    "    weight_val[labels_val==0] = 1.309028344\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition the dataset into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=2019)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.stack((q1_data, q2_data), axis=1)\n",
    "y = labels\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SPLIT, random_state=RNG_SEED)\n",
    "# Q1_train = X_train[:,0]\n",
    "# Q2_train = X_train[:,1]\n",
    "# Q1_test = X_test[:,0]\n",
    "# Q2_test = X_test[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [337176  17039  75113 ...,  41001 336218 115328] TEST: [283851 377233  35357 ..., 392228 325350 150065]\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in sss.split(X, y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Q1_train = X_train[:,0]\n",
    "# Q2_train = X_train[:,1]\n",
    "# Q1_test = X_test[:,0]\n",
    "# Q2_test = X_test[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#stacking Q1 and Q2\n",
    "Q1_train = np.vstack((X_train[:,0],X_train[:,1]))\n",
    "Q2_train = np.vstack((X_train[:,1],X_train[:,0]))\n",
    "Q1_test = np.vstack((X_test[:,0],X_test[:,1]))\n",
    "Q2_test = np.vstack((X_test[:,1],X_test[:,0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np.concatenate((y_train, y_train))\n",
    "y_test = np.concatenate((y_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(727722, 727722, 727722, 80858, 80858, 80858)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Q1_train),len(Q2_train),len(y_train),len(Q1_test),len(Q1_test),len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "re_weight = True \n",
    "\n",
    "if re_weight:\n",
    "    class_weight = {0: 1.309028344, 1: 0.472001959}\n",
    "else:\n",
    "    class_weight = None\n",
    "    \n",
    "    \n",
    "weight_val = np.ones(len(y_test))\n",
    "if re_weight:\n",
    "    weight_val *= 0.472001959\n",
    "    weight_val[y_test==0] = 1.309028344    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_convs():\n",
    "#v2\n",
    "    graph_in = Input(shape=(MAX_SEQUENCE_LENGTH,EMBEDDING_DIM))\n",
    "#     normalized_input = BatchNormalization()(graph_in)\n",
    "    \n",
    "    convs = []\n",
    "\n",
    "    for fsz in range(2,6): #conv > batch > max\n",
    "        conv = Conv1D(80, fsz,\n",
    "                      padding = 'valid', activation='relu')(graph_in)#\n",
    "        conv = Dropout(0.3)(conv)\n",
    "        conv = BatchNormalization()(conv)        \n",
    "        \n",
    "        pool = MaxPooling1D(pool_size=2)(conv)\n",
    "#renaming pool to conv to avoid mistakes\n",
    "#         conv = MaxPooling1D(pool_size=2)(conv)\n",
    "\n",
    "#         # v3 second layer convs\n",
    "#         conv = Conv1D(32, fsz,\n",
    "#                       padding = 'valid', activation='relu')(conv)#\n",
    "#         conv = BatchNormalization()(conv)        \n",
    "        \n",
    "#         pool = MaxPooling1D(pool_size=2)(conv)\n",
    "\n",
    "          \n",
    "        flatten = Flatten()(pool)\n",
    "#         pool = GlobalMaxPooling1D()(conv)\n",
    "        convs.append(flatten)\n",
    "\n",
    "    out = Merge(mode='concat')(convs) \n",
    "    graph = Model(input=graph_in,output=out)\n",
    "\n",
    "    return graph\n",
    "\n",
    "\n",
    "# v1\n",
    "#     graph_in = Input(shape=(MAX_SEQUENCE_LENGTH,EMBEDDING_DIM))\n",
    "#     convs = []\n",
    "\n",
    "#     for fsz in range(3,6):\n",
    "#         conv = Conv1D(256, fsz,strides=1,\n",
    "#                             padding = 'valid', activation='relu')(graph_in)#\n",
    "\n",
    "#         pool = MaxPooling1D(pool_length=2)(conv)\n",
    "#         flatten = Flatten()(pool)\n",
    "#         convs.append(flatten)\n",
    "\n",
    "#     out = Merge(mode='concat')(convs) \n",
    "#     graph = Model(input=graph_in,output=out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/qenv/lib/python2.7/site-packages/ipykernel/__main__.py:30: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/ubuntu/anaconda2/envs/qenv/lib/python2.7/site-packages/ipykernel/__main__.py:31: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"me..., inputs=Tensor(\"in...)`\n",
      "/home/ubuntu/anaconda2/envs/qenv/lib/python2.7/site-packages/ipykernel/__main__.py:34: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### add computation graph to question 1 embeddings\n",
    "graph = get_convs()\n",
    "\n",
    "Q1 = Sequential()\n",
    "Q1.add(Embedding(nb_words+1, \n",
    "                 EMBEDDING_DIM, \n",
    "                 weights=[word_embedding_matrix], \n",
    "                 input_length=MAX_SEQUENCE_LENGTH, \n",
    "                 trainable=False))\n",
    "\n",
    "\n",
    "Q1.add(graph)\n",
    "\n",
    "\n",
    "\n",
    "### Same ops for question 2\n",
    "\n",
    "Q2 = Sequential()\n",
    "Q2.add(Embedding(nb_words+1,\n",
    "                 EMBEDDING_DIM, \n",
    "                 weights=[word_embedding_matrix], \n",
    "                 input_length=MAX_SEQUENCE_LENGTH, \n",
    "                 trainable=False))\n",
    "\n",
    "\n",
    "Q2.add(graph)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Merge([Q1, Q2], mode='concat'))\n",
    "# concat = Concatenate([Q1, Q2])\n",
    "# model.add(concat)\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(150, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(200, activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='nadam', \n",
    "              metrics=['accuracy'])#, 'precision', 'recall', 'fbeta_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# graph.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model, checkpointing weights with best validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training at 2017-05-04 16:22:25.704432\n",
      "Train on 727722 samples, validate on 80858 samples\n",
      "Epoch 1/50\n",
      "727722/727722 [==============================] - 164s - loss: 0.3954 - acc: 0.7139 - val_loss: 0.3458 - val_acc: 0.6938\n",
      "Epoch 2/50\n",
      "727722/727722 [==============================] - 156s - loss: 0.3192 - acc: 0.7524 - val_loss: 0.3157 - val_acc: 0.7405\n",
      "Epoch 3/50\n",
      "727722/727722 [==============================] - 156s - loss: 0.2941 - acc: 0.7745 - val_loss: 0.2960 - val_acc: 0.7707\n",
      "Epoch 4/50\n",
      "727722/727722 [==============================] - 156s - loss: 0.2762 - acc: 0.7907 - val_loss: 0.2905 - val_acc: 0.7755\n",
      "Epoch 5/50\n",
      "727722/727722 [==============================] - 156s - loss: 0.2619 - acc: 0.8030 - val_loss: 0.2838 - val_acc: 0.7871\n",
      "Epoch 6/50\n",
      "727722/727722 [==============================] - 155s - loss: 0.2503 - acc: 0.8141 - val_loss: 0.2778 - val_acc: 0.7947\n",
      "Epoch 7/50\n",
      "727722/727722 [==============================] - 155s - loss: 0.2399 - acc: 0.8234 - val_loss: 0.2782 - val_acc: 0.8071\n",
      "Epoch 8/50\n",
      "727722/727722 [==============================] - 155s - loss: 0.2313 - acc: 0.8312 - val_loss: 0.2724 - val_acc: 0.7953\n",
      "Epoch 9/50\n",
      "727722/727722 [==============================] - 155s - loss: 0.2232 - acc: 0.8384 - val_loss: 0.2746 - val_acc: 0.7971\n",
      "Epoch 10/50\n",
      "727722/727722 [==============================] - 155s - loss: 0.2160 - acc: 0.8448 - val_loss: 0.2731 - val_acc: 0.8027\n",
      "Epoch 11/50\n",
      "727722/727722 [==============================] - 155s - loss: 0.2097 - acc: 0.8496 - val_loss: 0.2723 - val_acc: 0.8024\n",
      "Epoch 12/50\n",
      "727722/727722 [==============================] - 155s - loss: 0.2040 - acc: 0.8545 - val_loss: 0.2764 - val_acc: 0.8195\n",
      "Epoch 13/50\n",
      "727722/727722 [==============================] - 155s - loss: 0.1986 - acc: 0.8589 - val_loss: 0.2748 - val_acc: 0.8174\n",
      "Epoch 14/50\n",
      "727722/727722 [==============================] - 154s - loss: 0.1939 - acc: 0.8633 - val_loss: 0.2751 - val_acc: 0.8166\n",
      "Epoch 15/50\n",
      "727722/727722 [==============================] - 155s - loss: 0.1892 - acc: 0.8672 - val_loss: 0.2751 - val_acc: 0.8229\n",
      "Training ended at 2017-05-04 17:01:34.039019\n",
      "Minutes elapsed: 39.138904\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting training at\", datetime.datetime.now())\n",
    "t0 = time.time()\n",
    "\n",
    "MODEL_WEIGHTS_FILE = path+'weights/1d_conv_v2_kernel128x2_5_prepC_glove_randomshuffle_epoch_{epoch:02d}_val_loss_{val_loss:.2f}.h5'\n",
    "\n",
    "early_stopping =EarlyStopping(monitor='val_loss', patience=3)\n",
    "callbacks = [ModelCheckpoint(MODEL_WEIGHTS_FILE, monitor='val_loss', save_best_only=True),early_stopping]\n",
    "\n",
    "history = model.fit([data_1_train, data_2_train],\n",
    "                    labels_train,\n",
    "                    epochs=50,\n",
    "                    batch_size=2048,\n",
    "#                     validation_split=VALIDATION_SPLIT,\n",
    "                    validation_data = ([data_1_val, data_2_val],labels_val,weight_val),\n",
    "                    callbacks=callbacks,\n",
    "                    shuffle=True,\n",
    "                    class_weight=class_weight)\n",
    "\n",
    "\n",
    "t1 = time.time()\n",
    "print(\"Training ended at\", datetime.datetime.now())\n",
    "print(\"Minutes elapsed: %f\" % ((t1 - t0) / 60.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot training and validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFBCAYAAABuEzZyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhEJdREQkJP4/YtYJwR6P1ssAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5e5effacd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = pd.DataFrame({'epoch': [ i + 1 for i in history.epoch ],\n",
    "                    'training': history.history['loss'],\n",
    "                    'validation': history.history['val_loss']})\n",
    "ax = acc.ix[:,:].plot(x='epoch', figsize={5,8}, grid=True)\n",
    "ax.set_ylabel(\"loss\")\n",
    "ax.set_ylim([0.0,1.0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print best validation accuracy and epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "without cleaning: Maximum accuracy at epoch 8 = 0.8227\n",
    "with cleaning: Maximum accuracy at epoch 15 = 0.8268\n",
    "with cleaning and stratified: 0.8275"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Loss at epoch 11 = 0.2723\n"
     ]
    }
   ],
   "source": [
    "max_val_acc, idx = min((val, idx) for (idx, val) in enumerate(history.history['val_loss']))\n",
    "print('Minimum Loss at epoch', '{:d}'.format(idx+1), '=', '{:.4f}'.format(max_val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD the best weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !ls weights/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.load_weights(path+\"weights/1d_conv_v2_kernel128x2_5_prepC_glove_randomshuffle_epoch_10_val_loss_0.27.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model with best validation accuracy on the test partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loss, accuracy = model.evaluate([Q1_test, Q2_test], y_test) #, precision, recall, fbeta_score\n",
    "# print('')\n",
    "# print('loss      = {0:.4f}'.format(loss))\n",
    "# print('accuracy  = {0:.4f}'.format(accuracy))\n",
    "# # print('precision = {0:.4f}'.format(precision))\n",
    "# print('recall    = {0:.4f}'.format(recall))\n",
    "# print('F         = {0:.4f}'.format(fbeta_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-a525537457c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_preds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.90\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_preds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.98\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.98\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "val_preds = model.predict([data_1_val, data_2_val])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44603705516\n",
      "0.43719993048\n",
      "0.435078331711\n",
      "0.437864553618\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "print (log_loss(labels_val,val_preds))\n",
    "print (log_loss(labels_val,np.clip(val_preds,1-0.90,0.90)))\n",
    "print (log_loss(labels_val,np.clip(val_preds,1-0.98,0.98)))\n",
    "print (log_loss(labels_val,np.clip(val_preds,1-0.99,0.99)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q1_test_data = np.load(open(data_home+\"cache/\"+Q1_TESTING_DATA_FILE, 'rb'))\n",
    "q2_test_data = np.load(open(data_home+\"cache/\"+Q2_TESTING_DATA_FILE, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 49.7 s, sys: 9.61 s, total: 59.3 s\n",
      "Wall time: 5min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "preds = model.predict([q1_test_data,q2_test_data], batch_size=4096)\n",
    "preds_reverse = model.predict([q2_test_data,q1_test_data], batch_size=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = (preds + preds_reverse)/2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2345796, 1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clip =0.98\n",
    "\n",
    "# flattend = preds.flatten()\n",
    "\n",
    "clipped = preds.ravel()#np.clip(flattend,1-clip,clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>test_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000960</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.072982</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_duplicate  test_id\n",
       "0      0.000960        0\n",
       "1      0.072982        1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(data_home+'test.csv')\n",
    "\n",
    "sub = pd.DataFrame({'test_id': df_test['test_id'], 'is_duplicate': clipped})\n",
    "sub.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_name = \"subm/1d_conv_v2_kernel128x2_5_prepC_glove_randomshuffle_noclip.csv\"\n",
    "\n",
    "sub.to_csv(path+submission_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='subm/1d_conv_v2_kernel128x2_5_prepC_glove_randomshuffle_noclip.csv' target='_blank'>subm/1d_conv_v2_kernel128x2_5_prepC_glove_randomshuffle_noclip.csv</a><br>"
      ],
      "text/plain": [
       "/home/ubuntu/quora/subm/1d_conv_v2_kernel128x2_5_prepC_glove_randomshuffle_noclip.csv"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.lib.display import FileLink\n",
    "\n",
    "FileLink(submission_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:qenv]",
   "language": "python",
   "name": "conda-env-qenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
