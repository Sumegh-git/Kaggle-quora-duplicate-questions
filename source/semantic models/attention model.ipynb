{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention based model\n",
    "\n",
    "\n",
    "Based on the this post and google paper:\n",
    "https://explosion.ai/blog/deep-learning-formula-nlp\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime, time, json\n",
    "import keras \n",
    "\n",
    "\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Embedding, Dense, Dropout, Reshape, Merge, BatchNormalization, Lambda ,merge,SpatialDropout1D\n",
    "from keras.layers import Conv1D , Flatten, Input\n",
    "from keras.layers.pooling import MaxPooling1D\n",
    "from keras.layers.convolutional import ZeroPadding1D\n",
    "from keras.layers.wrappers import Bidirectional, TimeDistributed\n",
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "from keras.layers.merge import * \n",
    "from keras.layers.pooling import GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.initializers import he_normal\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "path = '/home/ubuntu/quora/'\n",
    "data_home = path +\"data/\"\n",
    "\n",
    "Q1_TRAINING_DATA_FILE = data_home+'cache/q1_train.npy'\n",
    "Q2_TRAINING_DATA_FILE = data_home+'cache/q2_train.npy'\n",
    "LABEL_TRAINING_DATA_FILE = data_home+'cache/label_train.npy'\n",
    "WORD_EMBEDDING_MATRIX_FILE = data_home+'cache/word_embedding_matrix.npy'\n",
    "NB_WORDS_DATA_FILE = data_home+'cache/nb_words.json'\n",
    "Q1_TESTING_DATA_FILE = 'q1_test.npy'\n",
    "Q2_TESTING_DATA_FILE = 'q2_test.npy'\n",
    "\n",
    "\n",
    "MODEL_WEIGHTS_FILE = path+'weights/conv_weights_v1.h5'\n",
    "MAX_SEQUENCE_LENGTH = 35\n",
    "EMBEDDING_DIM = 300\n",
    "VALIDATION_SPLIT = 0.1\n",
    "TEST_SPLIT = 0.1\n",
    "RNG_SEED = 13371447\n",
    "NB_EPOCHS = 25\n",
    "\n",
    "nr_hidden = 128\n",
    "drop_out=0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset, embedding matrix and word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q1_data = np.load(open(Q1_TRAINING_DATA_FILE, 'rb'))\n",
    "q2_data = np.load(open(Q2_TRAINING_DATA_FILE, 'rb'))\n",
    "labels = np.load(open(LABEL_TRAINING_DATA_FILE, 'rb'))\n",
    "word_embedding_matrix = np.load(open(WORD_EMBEDDING_MATRIX_FILE, 'rb'))\n",
    "with open(NB_WORDS_DATA_FILE, 'r') as f:\n",
    "    nb_words = json.load(f)['nb_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404290, 35), (404290, 35))"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_data.shape,q2_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition the dataset into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=2019)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.stack((q1_data, q2_data), axis=1)\n",
    "y = labels\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SPLIT, random_state=RNG_SEED)\n",
    "# Q1_train = X_train[:,0]\n",
    "# Q2_train = X_train[:,1]\n",
    "# Q1_test = X_test[:,0]\n",
    "# Q2_test = X_test[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [337176  17039  75113 ...,  41001 336218 115328] TEST: [283851 377233  35357 ..., 392228 325350 150065]\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in sss.split(X, y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Q1_train = X_train[:,0]\n",
    "Q2_train = X_train[:,1]\n",
    "Q1_test = X_test[:,0]\n",
    "Q2_test = X_test[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pretrained AND tuneable embeddings (skipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_embedder():\n",
    "    \n",
    "    embedder = Sequential()\n",
    "    embedder.add(Embedding(nb_words + 1, \n",
    "                     EMBEDDING_DIM, \n",
    "                     weights=[word_embedding_matrix], \n",
    "                     input_length=MAX_SEQUENCE_LENGTH, \n",
    "                     trainable=False,\n",
    "                    input_shape=(MAX_SEQUENCE_LENGTH,)))\n",
    "    embedder.add(TimeDistributed(\n",
    "                        Dense(\n",
    "                            200, #reducing dimensionality according to paper\n",
    "                            activation=None,\n",
    "                            use_bias=False,\n",
    "                            name='project')))\n",
    "    \n",
    "    return embedder\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_tuneable_embedder():\n",
    "    \n",
    "    embedder = Sequential()\n",
    "    \n",
    "    # projection embeddings ; \n",
    "    #not sure about their effectiveness but including them anyways; more details in the paper\n",
    "    \n",
    "    nr_tune = nb_words/2\n",
    "    \n",
    "    embedder.add(Lambda(lambda sent: sent % (nr_tune-1)+1,\n",
    "                     input_shape=(MAX_SEQUENCE_LENGTH,),\n",
    "                     output_shape=(MAX_SEQUENCE_LENGTH,)))\n",
    "    \n",
    "    embedder.add(Embedding(\n",
    "                    nr_tune,\n",
    "                    200,\n",
    "                    input_length=MAX_SEQUENCE_LENGTH,\n",
    "                    weights=None,\n",
    "                    name='tune',\n",
    "                    trainable=True))\n",
    "    embedder.add(SpatialDropout1D(drop_out))\n",
    "    \n",
    "    return embedder\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_bilstm():    \n",
    "    \n",
    "\n",
    "    encoder = Sequential()\n",
    "        \n",
    "    encoder.add(Bidirectional(LSTM(nr_hidden, return_sequences=True,\n",
    "                                             dropout=drop_out, recurrent_dropout=drop_out)\n",
    "                             ,input_shape=(MAX_SEQUENCE_LENGTH,200)\n",
    "                             ))\n",
    "\n",
    "    encoder.add(TimeDistributed(Dense(nr_hidden, activation='relu', kernel_initializer= he_normal())))\n",
    "    encoder.add(TimeDistributed(Dropout(drop_out)))\n",
    "    encoder.add(TimeDistributed(BatchNormalization()))\n",
    "\n",
    " \n",
    "        \n",
    "    \n",
    "    return encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/qenv/lib/python2.7/site-packages/ipykernel/__main__.py:10: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/ubuntu/anaconda2/envs/qenv/lib/python2.7/site-packages/ipykernel/__main__.py:14: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "q1 = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "q2 = Input(shape=(MAX_SEQUENCE_LENGTH,))#,EMBEDDING_DIM\n",
    "\n",
    "default_embedder = create_embedder()\n",
    "tuneable_embedder = create_tuneable_embedder()\n",
    "\n",
    "q1_pretrained_embed = default_embedder(q1)\n",
    "q1_tuneable_embed = tuneable_embedder(q1)\n",
    "q1_embed = merge([q1_pretrained_embed, q1_tuneable_embed], mode='sum')\n",
    "\n",
    "q2_pretrained_embed = default_embedder(q2)\n",
    "q2_tuneable_embed = tuneable_embedder(q2)\n",
    "q2_embed = merge([q2_pretrained_embed, q2_tuneable_embed], mode='sum')\n",
    "\n",
    "\n",
    "encoder = create_bilstm()\n",
    "\n",
    "q1_encoded = encoder(q1_embed)\n",
    "q2_encoded = encoder(q2_embed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pretrained Embeddings only (CURRENT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_bilstm():\n",
    "    \n",
    "    \n",
    "    Q = Sequential()\n",
    "    \n",
    "    # Embed\n",
    "    Q.add(Embedding(nb_words + 1, \n",
    "                     EMBEDDING_DIM, \n",
    "                     weights=[word_embedding_matrix], \n",
    "                     input_length=MAX_SEQUENCE_LENGTH, \n",
    "                     trainable=False,\n",
    "                    input_shape=(MAX_SEQUENCE_LENGTH,)))\n",
    "\n",
    "    #ToDo: projection\n",
    "\n",
    "    # Encode \n",
    "    Q.add(Bidirectional(LSTM(nr_hidden, return_sequences=True,\n",
    "                                             dropout=drop_out, recurrent_dropout=drop_out)))\n",
    "\n",
    "    Q.add(TimeDistributed(Dense(nr_hidden, activation='relu', kernel_initializer= he_normal())))#, init='he_normal'\n",
    "    Q.add(TimeDistributed(Dropout(drop_out)))\n",
    "    Q.add(TimeDistributed(BatchNormalization(),name='encoded'))\n",
    "\n",
    " \n",
    "        \n",
    "    \n",
    "    return Q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "q1 = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "q2 = Input(shape=(MAX_SEQUENCE_LENGTH,))#,EMBEDDING_DIM\n",
    "\n",
    "encoder = create_bilstm()\n",
    "\n",
    "q1_encoded = encoder(q1)\n",
    "q2_encoded = encoder(q2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Attention model\n",
    "\n",
    "attention_model = Sequential()\n",
    "attention_model.add(Dropout(drop_out,input_shape=(nr_hidden,)))\n",
    "\n",
    "attention_model.add(Dense(nr_hidden, name='attend1',kernel_initializer= he_normal(),\n",
    "            activation='relu'))\n",
    "attention_model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "attention_model.add(Dropout(drop_out))\n",
    "attention_model.add(Dense(nr_hidden, name='attend2',kernel_initializer= he_normal(),\n",
    "            activation='relu'))\n",
    "attention_model.add(BatchNormalization())\n",
    "\n",
    "attention_model = TimeDistributed(attention_model,name='attended')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attention1 = attention_model(q1_encoded)\n",
    "attention2 = attention_model(q2_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/qenv/lib/python2.7/site-packages/ipykernel/__main__.py:7: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "def _outer(AB):\n",
    "    att_ji = K.batch_dot(AB[1], K.permute_dimensions(AB[0], (0, 2, 1)))\n",
    "    return K.permute_dimensions(att_ji,(0, 2, 1))\n",
    "\n",
    "co_attention = merge([attention1, attention2],\n",
    "                     mode=_outer,\n",
    "                     output_shape=(MAX_SEQUENCE_LENGTH, MAX_SEQUENCE_LENGTH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def align(sentence, attention, transpose=False):\n",
    "        def _normalize_attention(attmat):\n",
    "            att = attmat[0]\n",
    "            mat = attmat[1]\n",
    "            if transpose:\n",
    "                att = K.permute_dimensions(att,(0, 2, 1))\n",
    "            # 3d softmax\n",
    "            e = K.exp(att - K.max(att, axis=-1, keepdims=True))\n",
    "            s = K.sum(e, axis=-1, keepdims=True)\n",
    "            sm_att = e / s\n",
    "            return K.batch_dot(sm_att, mat)\n",
    "        \n",
    "        return merge([attention, sentence], mode=_normalize_attention,\n",
    "                      output_shape=(MAX_SEQUENCE_LENGTH,nr_hidden))#, name='aligned') # Shape: (i, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/qenv/lib/python2.7/site-packages/ipykernel/__main__.py:14: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "align1 = align(q2_encoded, co_attention) #alignment is normalized attention for the other question\n",
    "align2 = align(q1_encoded, co_attention, transpose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comparison_model = Sequential()\n",
    "comparison_model.add(Dropout(drop_out, input_shape=(nr_hidden*2,)))\n",
    "\n",
    "comparison_model.add(Dense(nr_hidden, name='compare1',kernel_initializer=\"he_normal\",activation='relu'))\n",
    "comparison_model.add(BatchNormalization())\n",
    "comparison_model.add(Dropout(drop_out))\n",
    "\n",
    "comparison_model.add(Dense(nr_hidden, name='compare2',kernel_initializer=\"he_normal\",activation='relu'))\n",
    "comparison_model.add(BatchNormalization())\n",
    "\n",
    "comparison_model = TimeDistributed(comparison_model,name='compared')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features_by_comparison( sent, align):\n",
    "\n",
    "    result = comparison_model(merge([sent, align], mode='concat')) # Shape: (i, n)\n",
    "    avged = GlobalAveragePooling1D()(result)\n",
    "    maxed = GlobalMaxPooling1D()(result)\n",
    "    merged = merge([avged, maxed])\n",
    "    result = BatchNormalization()(merged)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/qenv/lib/python2.7/site-packages/ipykernel/__main__.py:3: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  app.launch_new_instance()\n",
      "/home/ubuntu/anaconda2/envs/qenv/lib/python2.7/site-packages/ipykernel/__main__.py:6: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "feats1 = get_features_by_comparison(q1_encoded, align1)\n",
    "feats2 = get_features_by_comparison(q2_encoded, align2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regressor_model = Sequential()\n",
    "\n",
    "regressor_model.add(Dropout(drop_out, input_shape=(nr_hidden*2,)))\n",
    "regressor_model.add(Dense(200, name='entail1',kernel_initializer='he_normal',activation='relu'))\n",
    "regressor_model.add(BatchNormalization())\n",
    "\n",
    "regressor_model.add(Dropout(drop_out))\n",
    "regressor_model.add(Dense(200, name='entail2', kernel_initializer='he_normal',activation='relu'))\n",
    "regressor_model.add(BatchNormalization())\n",
    "\n",
    "regressor_model.add(Dropout(drop_out))\n",
    "regressor_model.add(Dense(200, name='entail3', kernel_initializer='he_normal',activation='relu'))\n",
    "regressor_model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "regressor_model.add(Dropout(drop_out))\n",
    "regressor_model.add(Dense(200, name='entail4', kernel_initializer='he_normal',activation='relu'))\n",
    "regressor_model.add(BatchNormalization())\n",
    "\n",
    "regressor_model.add(Dense(1, name='entail_out', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/envs/qenv/lib/python2.7/site-packages/ipykernel/__main__.py:1: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "scores = regressor_model(merge([feats1, feats2], mode='concat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=[q1, q2], outputs=[scores])\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='nadam', \n",
    "              metrics=['accuracy'])#, 'precision', 'recall', 'fbeta_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_100 (InputLayer)           (None, 35)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_101 (InputLayer)           (None, 35)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "sequential_76 (Sequential)       (None, 35, 150)       35915550                                     \n",
      "____________________________________________________________________________________________________\n",
      "attended (TimeDistributed)       (None, 35, 150)       46500                                        \n",
      "____________________________________________________________________________________________________\n",
      "merge_77 (Merge)                 (None, 35, 35)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_78 (Merge)                 (None, 35, 150)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_79 (Merge)                 (None, 35, 150)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_80 (Merge)                 (None, 35, 300)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_82 (Merge)                 (None, 35, 300)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "compared (TimeDistributed)       (None, 35, 150)       69000                                        \n",
      "____________________________________________________________________________________________________\n",
      "global_average_pooling1d_15 (Glo (None, 150)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "global_max_pooling1d_15 (GlobalM (None, 150)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "global_average_pooling1d_16 (Glo (None, 150)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "global_max_pooling1d_16 (GlobalM (None, 150)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_81 (Merge)                 (None, 150)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_83 (Merge)                 (None, 150)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNor (None, 150)           600                                          \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNor (None, 150)           600                                          \n",
      "____________________________________________________________________________________________________\n",
      "merge_84 (Merge)                 (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "sequential_79 (Sequential)       (None, 1)             184201                                       \n",
      "====================================================================================================\n",
      "Total params: 36,216,451\n",
      "Trainable params: 884,151\n",
      "Non-trainable params: 35,332,300\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model, checkpointing weights with best validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training at 2017-04-25 20:30:54.419606\n",
      "Train on 363861 samples, validate on 40429 samples\n",
      "Epoch 1/15\n",
      "120832/363861 [========>.....................] - ETA: 495s - loss: 0.6731 - acc: 0.5987"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-221-21325a4bb766>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mQ1_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ2_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     callbacks=callbacks)\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training ended at\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/envs/qenv/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/envs/qenv/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1139\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1142\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/envs/qenv/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/envs/qenv/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/envs/qenv/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m             \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Starting training at\", datetime.datetime.now())\n",
    "t0 = time.time()\n",
    "\n",
    "\n",
    "MODEL_WEIGHTS_FILE = path+'weights/attention_v1.h5'\n",
    "\n",
    "\n",
    "callbacks = [ModelCheckpoint(MODEL_WEIGHTS_FILE, monitor='val_acc', save_best_only=True)]\n",
    "\n",
    "history = model.fit([Q1_train, Q2_train],\n",
    "                    y_train,\n",
    "                    epochs=15,\n",
    "                    batch_size=1024,\n",
    "                    validation_data = ([Q1_test, Q2_test],y_test),\n",
    "                    callbacks=callbacks)\n",
    "t1 = time.time()\n",
    "print(\"Training ended at\", datetime.datetime.now())\n",
    "print(\"Minutes elapsed: %f\" % ((t1 - t0) / 60.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot training and validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acc = pd.DataFrame({'epoch': [ i + 1 for i in history.epoch ],\n",
    "                    'training': history.history['acc'],\n",
    "                    'validation': history.history['val_acc']})\n",
    "ax = acc.ix[:,:].plot(x='epoch', figsize={5,8}, grid=True)\n",
    "ax.set_ylabel(\"accuracy\")\n",
    "ax.set_ylim([0.0,1.0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"Starting training at\", datetime.datetime.now())\n",
    "t0 = time.time()\n",
    "\n",
    "model.optimizer.lr = 1e-4\n",
    "MODEL_WEIGHTS_FILE2 = path+'weights/attention_v1_lr1e4.h5'\n",
    "\n",
    "\n",
    "callbacks = [ModelCheckpoint(MODEL_WEIGHTS_FILE2, monitor='val_acc', save_best_only=True)]\n",
    "\n",
    "history2 = model.fit([Q1_train, Q2_train],\n",
    "                    y_train,\n",
    "                    epochs=15,\n",
    "                    batch_size=64,\n",
    "                    validation_split=VALIDATION_SPLIT,\n",
    "                    callbacks=callbacks)\n",
    "t1 = time.time()\n",
    "print(\"Training ended at\", datetime.datetime.now())\n",
    "print(\"Minutes elapsed: %f\" % ((t1 - t0) / 60.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print best validation accuracy and epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "without cleaning: Maximum accuracy at epoch 8 = 0.8227\n",
    "with cleaning: Maximum accuracy at epoch 15 = 0.8268\n",
    "with cleaning and stratified: 0.8275"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum accuracy at epoch 10 = 0.8167\n"
     ]
    }
   ],
   "source": [
    "max_val_acc, idx = max((val, idx) for (idx, val) in enumerate(history.history['val_acc']))\n",
    "print('Maximum accuracy at epoch', '{:d}'.format(idx+1), '=', '{:.4f}'.format(max_val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model with best validation accuracy on the test partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40416/40429 [============================>.] - ETA: 0s\n",
      "loss      = 0.4085\n",
      "accuracy  = 0.8144\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(MODEL_WEIGHTS_FILE)\n",
    "loss, accuracy = model.evaluate([Q1_test, Q2_test], y_test) #, precision, recall, fbeta_score\n",
    "print('')\n",
    "print('loss      = {0:.4f}'.format(loss))\n",
    "print('accuracy  = {0:.4f}'.format(accuracy))\n",
    "# print('precision = {0:.4f}'.format(precision))\n",
    "# print('recall    = {0:.4f}'.format(recall))\n",
    "# print('F         = {0:.4f}'.format(fbeta_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict([Q1_test, Q2_test])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.408477160842\n",
      "0.443975123093\n",
      "0.418641389755\n",
      "0.412511057188\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "print (log_loss(y_test,preds))\n",
    "print (log_loss(y_test,np.clip(preds,1-0.82,0.82)))\n",
    "print (log_loss(y_test,np.clip(preds,1-0.90,0.90)))\n",
    "print (log_loss(y_test,np.clip(preds,1-0.93,0.93)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q1_test_data = np.load(open(data_home+\"cache/\"+Q1_TESTING_DATA_FILE, 'rb'))\n",
    "q2_test_data = np.load(open(data_home+\"cache/\"+Q2_TESTING_DATA_FILE, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    5,   22,    1, 1990,  802, 1222,   13,  352,   29,\n",
       "        1611,  802], dtype=int32),\n",
       " array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    5,   22,    1, 1990,  802, 1222,   13,  352,   29,\n",
       "        1611,  802], dtype=int32))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_test_data[0],q1_test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 55s, sys: 1min 15s, total: 7min 11s\n",
      "Wall time: 7min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = model.predict([q1_test_data,q2_test_data], batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2345796, 1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clip =0.90\n",
    "\n",
    "submission_name = \"subm/deep_conv_v1_c90.csv\"\n",
    "flattend = preds.flatten()\n",
    "\n",
    "clipped = np.clip(flattend,1-clip,clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>test_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.449301</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_duplicate  test_id\n",
       "0      0.100000        0\n",
       "1      0.449301        1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(data_home+'test.csv')\n",
    "\n",
    "sub = pd.DataFrame({'test_id': df_test['test_id'], 'is_duplicate': clipped})\n",
    "sub.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.to_csv(path+submission_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='subm/deep_conv_v1_c90.csv' target='_blank'>subm/deep_conv_v1_c90.csv</a><br>"
      ],
      "text/plain": [
       "/home/ubuntu/quora/subm/deep_conv_v1_c90.csv"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.lib.display import FileLink\n",
    "\n",
    "FileLink(submission_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:qenv]",
   "language": "python",
   "name": "conda-env-qenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
