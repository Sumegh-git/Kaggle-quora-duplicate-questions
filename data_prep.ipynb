{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quora question pairs: data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla K80 (CNMeM is enabled with initial size: 95.0% of memory, cuDNN 5103)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import csv, json\n",
    "from zipfile import ZipFile\n",
    "from os.path import expanduser, exists\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.data_utils import get_file\n",
    "\n",
    "\n",
    "\n",
    "import sys\n",
    "import os \n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "import spacy\n",
    "\n",
    "# import utils \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "from IPython.lib.display import FileLink\n",
    "\n",
    "\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/ubuntu/quora/'\n",
    "data_home = path +\"data/\"\n",
    "\n",
    "\n",
    "KERAS_DATASETS_DIR = data_home+\"cache/\"\n",
    "\n",
    "# KERAS_DATASETS_DIR = expanduser('~/.keras/datasets/')\n",
    "QUESTION_PAIRS_FILE_URL = 'http://qim.ec.quoracdn.net/quora_duplicate_questions.tsv'\n",
    "QUESTION_PAIRS_FILE = 'quora_duplicate_questions.tsv'\n",
    "GLOVE_ZIP_FILE_URL = 'http://nlp.stanford.edu/data/glove.840B.300d.zip'\n",
    "GLOVE_ZIP_FILE = 'glove.840B.300d.zip'\n",
    "GLOVE_FILE = 'glove.840B.300d.txt'\n",
    "Q1_TRAINING_DATA_FILE = 'q1_train.npy'\n",
    "Q2_TRAINING_DATA_FILE = 'q2_train.npy'\n",
    "Q1_TESTING_DATA_FILE = 'q1_test.npy'\n",
    "Q2_TESTING_DATA_FILE = 'q2_test.npy'\n",
    "\n",
    "\n",
    "LABEL_TRAINING_DATA_FILE = 'label_train.npy'\n",
    "WORD_EMBEDDING_MATRIX_FILE = 'word_embedding_matrix.npy'\n",
    "NB_WORDS_DATA_FILE = 'nb_words.json'\n",
    "MAX_NB_WORDS = 200000\n",
    "MAX_SEQUENCE_LENGTH = 35#25\n",
    "EMBEDDING_DIM = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and extract questions pairs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = pd.read_csv(data_home+'train.csv' , encoding='utf-8'   )\n",
    "# df_test = pd.read_csv(data_home+'test.csv' , encoding='utf-8'   )\n",
    "\n",
    "############ read cleaned data ##########\n",
    "df_train = pd.read_csv(data_home+'train_clean_vB.csv' , encoding='utf-8'   )\n",
    "df_test = pd.read_csv(data_home+'test_clean_vB.csv' , encoding='utf-8'   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_id        0\n",
       "q1_clean_vB    0\n",
       "q2_clean_vB    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = df_train.fillna(\"empty\")\n",
    "df_test = df_test.fillna(\"empty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_clean_vB</th>\n",
       "      <th>q2_clean_vB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>What is step by step guide to invest in share ...</td>\n",
       "      <td>What is step by step guide to invest in share ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>What is story of Kohinoor Koh - i - Noor Diamond?</td>\n",
       "      <td>What would happen if Indian government stole K...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2  is_duplicate  \\\n",
       "0   0     1     2             0   \n",
       "1   1     3     4             0   \n",
       "\n",
       "                                         q1_clean_vB  \\\n",
       "0  What is step by step guide to invest in share ...   \n",
       "1  What is story of Kohinoor Koh - i - Noor Diamond?   \n",
       "\n",
       "                                         q2_clean_vB  \n",
       "0  What is step by step guide to invest in share ...  \n",
       "1  What would happen if Indian government stole K...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting rid of original question1 and question2 columns for simplicity\n",
    "\n",
    "df_train['question1']  =  df_train.q1_clean_vB\n",
    "df_train['question2'] =  df_train.q2_clean_vB\n",
    "\n",
    "df_test['question1'] =  df_test.q1_clean_vB\n",
    "df_test['question2'] =  df_test.q2_clean_vB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = df_train.drop([\"q1_clean_vB\",\"q2_clean_vB\"],axis=1)\n",
    "df_test = df_test.drop([\"q1_clean_vB\",\"q2_clean_vB\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df_train['question1'] = df_train['question1'].apply(lambda x: x.encode('utf-8'))\n",
    "# df_train['question2'] = df_train['question2'].apply(lambda x: x.encode('utf-8'))\n",
    "\n",
    "# df_test['question1'] = df_test['question1'].apply(lambda x: x.encode('utf-8'))\n",
    "# df_test['question2'] = df_test['question2'].apply(lambda x: x.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>What is the story of Kohinoor (Koh i Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>find the remainder when [math]23^{24}[/math] i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>Which one dissolve in water quickly sugar, sal...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2  is_duplicate  \\\n",
       "0   0     1     2             0   \n",
       "1   1     3     4             0   \n",
       "2   2     5     6             0   \n",
       "3   3     7     8             0   \n",
       "4   4     9    10             0   \n",
       "\n",
       "                                           question1  \\\n",
       "0  What is the step by step guide to invest in sh...   \n",
       "1  What is the story of Kohinoor (Koh i Noor) Dia...   \n",
       "2  How can I increase the speed of my internet co...   \n",
       "3  Why am I mentally very lonely? How can I solve...   \n",
       "4  Which one dissolve in water quickly sugar, sal...   \n",
       "\n",
       "                                           question2  \n",
       "0  What is the step by step guide to invest in sh...  \n",
       "1  What would happen if the Indian government sto...  \n",
       "2  How can Internet speed be increased by hacking...  \n",
       "3  find the remainder when [math]23^{24}[/math] i...  \n",
       "4            Which fish would survive in salt water?  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "question1_train = df_train.question1.astype(str)\n",
    "question2_train = df_train.question2.astype(str)\n",
    "is_duplicate = df_train.is_duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "question1_test = df_test.question1.astype(str)\n",
    "question2_test = df_test.question2.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question pairs: training: 404290 test: 2345796\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Question pairs: training: %d test:' % len(question1_train)  , len(question1_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build tokenized word index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2345796"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use test questions also to create tokens \n",
    "\n",
    "train_questions = question1_train + \" \"+ question2_train\n",
    "test_questions = question1_test + \" \"+ question2_test\n",
    "\n",
    "len(test_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = train_questions.append( test_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is best medication equation erectile dysfunction? How do I out get rid of Erectile Dysfunction?'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_questions[2345795]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50.8 s, sys: 20 ms, total: 50.8 s\n",
      "Wall time: 50.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, lower=True)\n",
    "tokenizer.fit_on_texts(questions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating reverse index to word map (for paraphrase generation (NOT DONE))\n",
    "# inv_map = {v: k for k, v in tokenizer.word_index.iteritems()}\n",
    "# with open(data_home+\"cache/tokenizer_reverse_word_index.dat\",'wb') as handle:\n",
    "#     pickle.dump(inv_map,handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words in index: 120773\n",
      "CPU times: user 6.1 s, sys: 20 ms, total: 6.12 s\n",
      "Wall time: 6.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "question1_word_sequences = tokenizer.texts_to_sequences(question1_train)\n",
    "question2_word_sequences = tokenizer.texts_to_sequences(question2_train)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "print(\"Words in index: %d\" % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 1252, 60, 1252, 2919, 7, 577, 6, 757, 365]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question2_word_sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.2 s, sys: 404 ms, total: 40.6 s\n",
      "Wall time: 40.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "testq1_word_sequences = tokenizer.texts_to_sequences(question1_test)\n",
    "testq2_word_sequences = tokenizer.texts_to_sequences(question2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and process GloVe embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# if not exists(KERAS_DATASETS_DIR + GLOVE_ZIP_FILE):\n",
    "#     zipfile = ZipFile(get_file(GLOVE_ZIP_FILE, GLOVE_ZIP_FILE_URL))\n",
    "#     zipfile.extract(GLOVE_FILE, path=KERAS_DATASETS_DIR)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is how a word vector looks like:\n",
    "\n",
    "['melodies', '0.39203', '0.76391', '-0.27438', '0.20478', '0.28002', '0.15006', '0.27144', '0.03625', '-0.005431', '0.79186', '0.97261', '0.32796', '-0.16917', '0.37354', '0.35588', '0.05971', '0.066368', '0.39296', '-0.034228', '-0.16004', '-0.3086', '0.61723', '0.13225', '-0.30863', '-0.16481', '0.18971', '0.36708', '0.4132', '0.8603', '-0.10542', '0.28735', '-0.43696', '-0.64395', '-0.16088', '0.32564', '-0.030691', '-0.64959', '0.28413', '0.42177', '0.12257', '-0.11246', '-0.084039', '-0.13831', '0.42894', '0.59371', ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing glove.840B.300d.txt\n",
      "CPU times: user 2min 11s, sys: 3.08 s, total: 2min 14s\n",
      "Wall time: 2min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# print(\"Processing\", GLOVE_FILE)\n",
    "# embeddings_index = {}\n",
    "\n",
    "# with open(KERAS_DATASETS_DIR + GLOVE_FILE) as f: #, encoding='utf-8'\n",
    "#     for line in f:\n",
    "#         values = line.split(' ')\n",
    "#         word = values[0]\n",
    "#         embedding = np.asarray(values[1:], dtype='float32')\n",
    "#         embeddings_index[word] = embedding\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext Cython\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "with open(data_home+\"cache/embeddings_index.npy\", 'rb') as handle:\n",
    "    embeddings_index = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word embeddings: 2196016\n"
     ]
    }
   ],
   "source": [
    "print('Word embeddings: %d' % len(embeddings_index))\n",
    "# embeddings_index[\"fuss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.save(open(data_home+\"cache/embeddings_index.npy\", 'wb'), embeddings_index)\n",
    "# embeddings_index = np.load(open(emb_index_path, 'rb'))\n",
    "\n",
    "# with open(data_home+\"cache/embeddings_index.npy\", 'wb') as handle:\n",
    "#     pickle.dump(embeddings_index, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "\n",
    "# print a == b    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare word embedding matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Null word embeddings: 65893 (v1 cleaning)\n",
    "Null word embeddings: 32955 (v2 cleaning) halved!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120773"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(MAX_NB_WORDS, len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 424 ms, sys: 60 ms, total: 484 ms\n",
      "Wall time: 481 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "nb_words = min(MAX_NB_WORDS, len(word_index))\n",
    "word_embedding_matrix = np.zeros((nb_words + 1, EMBEDDING_DIM))\n",
    "no_embeddings = []\n",
    "\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i > MAX_NB_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        word_embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        no_embeddings.append(word)\n",
    "        word_embedding_matrix[i] = np.random.rand(300)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null word embeddings: 33420\n"
     ]
    }
   ],
   "source": [
    "print('Null word embeddings: %d' % len(no_embeddings))#np.sum(np.sum(word_embedding_matrix, axis=1) == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['murwara',\n",
       " 'daiict',\n",
       " 'utnapishtim',\n",
       " 'devonians',\n",
       " 'fawx',\n",
       " 'paiza',\n",
       " 'turram',\n",
       " 'lottoland',\n",
       " 'chanthaburi',\n",
       " 'googlenet',\n",
       " 'zandikhohlisa',\n",
       " 'gazatted',\n",
       " 'freesteamgifts',\n",
       " 'naturopathix',\n",
       " 'throwaround',\n",
       " 'vologda',\n",
       " 'ctk3200',\n",
       " 'girokonto',\n",
       " 'targu',\n",
       " 'starboy',\n",
       " 'krampusnacht',\n",
       " 'naache',\n",
       " '2300mhz',\n",
       " 'movietv',\n",
       " 'trivikram',\n",
       " '27i',\n",
       " 'bhubaneshwar',\n",
       " 'oct14',\n",
       " 't250si',\n",
       " 't250sl',\n",
       " 'imporatnace',\n",
       " 'istributed',\n",
       " 'diomand',\n",
       " 'mclaurin',\n",
       " 'yaghan',\n",
       " 'ohhio',\n",
       " 'issual',\n",
       " 'thamirabarani',\n",
       " 'jspatch',\n",
       " 'pgdhrm',\n",
       " 'ronalds',\n",
       " 'unlearnable',\n",
       " 'twenty19',\n",
       " 'kayasthas',\n",
       " 'vasuda',\n",
       " 'inorgnc',\n",
       " 'avma',\n",
       " 'iraiva',\n",
       " 'stavara',\n",
       " 'borstar',\n",
       " '2phz',\n",
       " 'sy0',\n",
       " '900eur',\n",
       " 'torqouise',\n",
       " 'oliveboard',\n",
       " 'chandrabati',\n",
       " 'pinth',\n",
       " '28teeth',\n",
       " '180deggrid',\n",
       " 'phoritto',\n",
       " 'barbro',\n",
       " 'censys',\n",
       " 'oritani',\n",
       " 'regstn',\n",
       " 'catracha',\n",
       " 'dlvrit',\n",
       " 'p207tx',\n",
       " 'uov',\n",
       " 'cryolife',\n",
       " 'sizr',\n",
       " 'vrushali',\n",
       " 'shinawatra',\n",
       " 'buuz',\n",
       " 'class11th',\n",
       " '9w1',\n",
       " 'pandodaily',\n",
       " 'moonmeander',\n",
       " '9w8',\n",
       " 'vilom',\n",
       " 'raahaten',\n",
       " '598s',\n",
       " 'zuin',\n",
       " 'cinemedia',\n",
       " 'isyx',\n",
       " 'quorarian',\n",
       " 'folarin',\n",
       " 'picaroworld',\n",
       " 'synaptol',\n",
       " 'sathyabhama',\n",
       " 'alagio',\n",
       " 'statusqo',\n",
       " 'partitiate',\n",
       " '6qn',\n",
       " 'religuous',\n",
       " 'khrap',\n",
       " 'angelfall',\n",
       " 'selfi',\n",
       " 'niammy',\n",
       " 'cougars69',\n",
       " 'esophagal',\n",
       " 'katelynne',\n",
       " 'helpbob',\n",
       " 'viete',\n",
       " 'bilzerian',\n",
       " 'mastec',\n",
       " 'bockscar',\n",
       " 'd5500',\n",
       " 'mastek',\n",
       " 'forevermark',\n",
       " 'rewardz',\n",
       " 'evidaayirunnu',\n",
       " 'ahwazi',\n",
       " 'biolgy',\n",
       " 'pogathey',\n",
       " '32gg',\n",
       " 'dousunda',\n",
       " 'skeletool',\n",
       " 'medibang',\n",
       " 'bbnl',\n",
       " 'kuamari',\n",
       " 'nthan',\n",
       " 'tecphlie',\n",
       " 'mishri',\n",
       " 'pratha',\n",
       " 'bhaang',\n",
       " 'rhca',\n",
       " 'testsys',\n",
       " 'xat2017',\n",
       " '975l',\n",
       " 'sx376b',\n",
       " 'hso3',\n",
       " 'relpacing',\n",
       " 'thaad',\n",
       " 'thaai',\n",
       " 'na2so3',\n",
       " 'socho',\n",
       " 'spreecommerce',\n",
       " 'ajaya',\n",
       " 'wifikill2',\n",
       " 'incropera',\n",
       " 'puche',\n",
       " 'khaasdaar',\n",
       " 'srabon',\n",
       " 'rtwapne',\n",
       " 'recyify',\n",
       " 'prulu',\n",
       " 'hilali',\n",
       " 'adfurther',\n",
       " 'aadam',\n",
       " 'subtills',\n",
       " 'pmfby',\n",
       " 'grailed',\n",
       " 'chyavanprash',\n",
       " 'kumada',\n",
       " 'gcet',\n",
       " 'guansen',\n",
       " '210205',\n",
       " 'papertronics',\n",
       " 'miyaki',\n",
       " 'engility',\n",
       " 'ir6',\n",
       " 'i7559',\n",
       " 'djaevleoen',\n",
       " 'numlk',\n",
       " 'techstartups',\n",
       " 'brokerlinking',\n",
       " 'placments',\n",
       " 'ozium',\n",
       " 'teewe',\n",
       " 'jeor',\n",
       " 'badaruddin',\n",
       " 'amazonsmile',\n",
       " 'somatrophin',\n",
       " 'c2160',\n",
       " 'oclaro',\n",
       " 'sirasana',\n",
       " 'bundelkhand',\n",
       " 'monowitz',\n",
       " 'recyclerview',\n",
       " 'coloneus',\n",
       " 'sellenium',\n",
       " 'morevisas',\n",
       " 'gbpuat',\n",
       " 'pllsss',\n",
       " 'i8552',\n",
       " 'wothy',\n",
       " 'shudhu',\n",
       " 'famoustylishnails',\n",
       " 'jagadhri',\n",
       " 'deliveey',\n",
       " '1a111in',\n",
       " 'quanttative',\n",
       " 'anxietydisorder',\n",
       " 'keynesians',\n",
       " 'for4000sq',\n",
       " 'freemyapps',\n",
       " 'churchofsatan',\n",
       " 'spellathon',\n",
       " 'photosin',\n",
       " 'darkon',\n",
       " 'bseb',\n",
       " 'basanthali',\n",
       " 'monsterusers',\n",
       " 'ointernet',\n",
       " '568568568568',\n",
       " 'novasure',\n",
       " 'vidhur',\n",
       " 'unlinke',\n",
       " 'sentellas',\n",
       " 'anyboudy',\n",
       " 'fyers',\n",
       " 'c4h10',\n",
       " 'bses',\n",
       " 'todefence',\n",
       " 'emberton',\n",
       " 'kotlin',\n",
       " 'acof',\n",
       " 'mollars',\n",
       " 'sunpharma',\n",
       " 'mangoe',\n",
       " '30z',\n",
       " 'iquanta',\n",
       " 'udeg',\n",
       " 'monitormojo',\n",
       " 'ferriday',\n",
       " 'givewell',\n",
       " 'dadhichi',\n",
       " 'kissflow',\n",
       " 'airlineprices',\n",
       " 'horodecki',\n",
       " 'bhau',\n",
       " 'badmin',\n",
       " 'livepedia',\n",
       " 'synchronoss',\n",
       " 'wholesalefash',\n",
       " 'hydroxydopamine',\n",
       " '1080x2560',\n",
       " 'transportmantra',\n",
       " 'ubns',\n",
       " 'chargebee',\n",
       " 'lmgtf',\n",
       " 'loret',\n",
       " '303585',\n",
       " 'neopentane',\n",
       " 'sanddornbalance',\n",
       " 'fukatsu',\n",
       " 'urgit',\n",
       " 'omran',\n",
       " 'tetrachlorodibenzo',\n",
       " '14maths',\n",
       " 'mehrab',\n",
       " 'bluerock',\n",
       " 'chaid',\n",
       " 'rabinder',\n",
       " 'anfis',\n",
       " 'datapower',\n",
       " 'goodrec',\n",
       " 'arshini',\n",
       " 'hipparchus',\n",
       " 'tetrabutylammoniumbromide',\n",
       " 'amatriain',\n",
       " 'vanellope',\n",
       " 'shreeman',\n",
       " 'abolisihed',\n",
       " 'papasamyam',\n",
       " 'forfishingvideos',\n",
       " 'matram',\n",
       " 'nh2nh2',\n",
       " 'demonitasation',\n",
       " 'huepool',\n",
       " 'clashbot',\n",
       " 'mensutra',\n",
       " 'mrlposnet',\n",
       " 'subbaraj',\n",
       " 'kalewadi',\n",
       " 'hio4',\n",
       " 'bioreference',\n",
       " 'resticker',\n",
       " 'mandula',\n",
       " 'studentlist',\n",
       " 'wavii',\n",
       " 'dimitrova',\n",
       " 'pularin',\n",
       " 'flightsiming',\n",
       " 'langara',\n",
       " 'innitwould',\n",
       " 'tayyibah',\n",
       " '3558u',\n",
       " 'mythomagic',\n",
       " 'bimtech',\n",
       " 'brexpiprazole',\n",
       " 'noresourceerror',\n",
       " 'pasquotank',\n",
       " 'wvm',\n",
       " 'shyamali',\n",
       " 'simbalochan',\n",
       " 'jadavpur',\n",
       " 'pushbullet',\n",
       " 'groupme',\n",
       " 'bodhidharman',\n",
       " 'tadrishi',\n",
       " 'eiichiro',\n",
       " 'fretwell',\n",
       " 'upssc',\n",
       " 'yalom',\n",
       " 'falluja',\n",
       " 'cuhk',\n",
       " 'backpapers',\n",
       " 'denbury',\n",
       " 'unreciprocating',\n",
       " 'pollachi',\n",
       " 'bhisma',\n",
       " 'kahlon',\n",
       " 'mallaya',\n",
       " 'habiru',\n",
       " 'arpdau',\n",
       " 'jasprit',\n",
       " 'jungwirth',\n",
       " 'ahimsavadi',\n",
       " 'shibpur',\n",
       " 'tulsidas',\n",
       " 'digyton',\n",
       " 'jalpaiguri',\n",
       " 'varifing',\n",
       " 'forname',\n",
       " 'sortex',\n",
       " 'registan',\n",
       " 'tigrinya',\n",
       " 'shacket',\n",
       " 'mutlicellular',\n",
       " 'didm',\n",
       " 'didw',\n",
       " 'mewto',\n",
       " 'indiape',\n",
       " 'psocids',\n",
       " 'topcoder',\n",
       " 'digambar',\n",
       " 'arnorld',\n",
       " 'postcolonialists',\n",
       " 'binarysearch',\n",
       " 'howtonotgiveafuck',\n",
       " 'dashnaw',\n",
       " 'fictioned',\n",
       " 'brabourne',\n",
       " 'bhadotri',\n",
       " 'gsds',\n",
       " 'progrmm',\n",
       " '96176434603',\n",
       " 'alecturer',\n",
       " 'usacontact',\n",
       " 'stuterring',\n",
       " 'fuelband',\n",
       " 'ventablack',\n",
       " 'narahalli',\n",
       " 'hetchy',\n",
       " 'chandos',\n",
       " 'bannig',\n",
       " 'emem',\n",
       " 'eknath',\n",
       " '1milion',\n",
       " 'wolpert',\n",
       " 'bhagwant',\n",
       " 'gettimer',\n",
       " 'littelfuse',\n",
       " 'konsus',\n",
       " 'eetoo',\n",
       " 'exmormons',\n",
       " 'returnship',\n",
       " 'chandresh',\n",
       " 'dhakka',\n",
       " 'haauhow',\n",
       " 'antiform',\n",
       " 'thangameengal',\n",
       " 'wynk',\n",
       " 'wonderware',\n",
       " 'gatewayabroad',\n",
       " 'dgmo',\n",
       " 'leatherup',\n",
       " 'carpopedal',\n",
       " 'hackathone',\n",
       " 'ouchi',\n",
       " 'gradeaundera',\n",
       " 'azoff',\n",
       " 'kodava',\n",
       " 'jinbo',\n",
       " 'remustering',\n",
       " 'pregrade',\n",
       " 'pimr',\n",
       " 'noroot',\n",
       " 'productionrs',\n",
       " 'vohra',\n",
       " 'pimi',\n",
       " 'bluemail',\n",
       " 'guterres',\n",
       " 'ampiclox',\n",
       " 'kues',\n",
       " 'cs157',\n",
       " 'baggrey',\n",
       " 'nrsc',\n",
       " 'pandwas',\n",
       " 'linkdin',\n",
       " 'dhaakad',\n",
       " 'dream11',\n",
       " 'tadoussac',\n",
       " 'saveetha',\n",
       " 'applicationcontext',\n",
       " 'khukhris',\n",
       " 'rajaji',\n",
       " 'e015tc',\n",
       " 'edisha',\n",
       " 'navaratna',\n",
       " '2posts',\n",
       " 'manterrupting',\n",
       " 'yzr',\n",
       " 'sowmay',\n",
       " 'haloarene',\n",
       " 'ivec',\n",
       " 'uoh',\n",
       " 'gooduniversities',\n",
       " 'shelob',\n",
       " 'bringbacks',\n",
       " 'broomhilda',\n",
       " '76deg',\n",
       " 'nevile',\n",
       " 'ichangemycity',\n",
       " 'anjar',\n",
       " 'manyeth',\n",
       " 'nanophysics',\n",
       " 'khamba',\n",
       " 'albatraoz',\n",
       " 'composelabs',\n",
       " 'amrut',\n",
       " 'superscore',\n",
       " 'irtc',\n",
       " '777x',\n",
       " 'shishou',\n",
       " 'exanplae',\n",
       " 'howaboutwe',\n",
       " 'wankhade',\n",
       " 'qbit',\n",
       " 'ole55e6v',\n",
       " '0x80070424',\n",
       " 'lucideus',\n",
       " 'bhopali',\n",
       " 'jplt',\n",
       " 'dowloands',\n",
       " 'ioi2017',\n",
       " 'borowitz',\n",
       " 'topologie',\n",
       " 'escapethecity',\n",
       " 'samcro',\n",
       " 'routofy',\n",
       " '0x800f081f',\n",
       " 'dioxsyn',\n",
       " 'alapacia',\n",
       " 'rudrabhishek',\n",
       " 'xtz125',\n",
       " 'flockof',\n",
       " 'kjedahls',\n",
       " 'explorate',\n",
       " 'holay',\n",
       " 'nurunatl',\n",
       " 'savilian',\n",
       " 'utiltarianism',\n",
       " 'moriarity',\n",
       " 'braingasmic',\n",
       " 'bubbli',\n",
       " 'celcon',\n",
       " 'bfsi',\n",
       " 'commoncrawl',\n",
       " '269300',\n",
       " 'artical368',\n",
       " 'dormis',\n",
       " 'fucher',\n",
       " 'doordharsan',\n",
       " 'mh370',\n",
       " 'sarif',\n",
       " 'satbara',\n",
       " 'murthys',\n",
       " 'jccsf',\n",
       " 'litrerature',\n",
       " 'mechaincal',\n",
       " 'vvison',\n",
       " 'joy2key',\n",
       " 'jyotiba',\n",
       " 'spreadly',\n",
       " 'nrhm',\n",
       " 'soekarno',\n",
       " 'kumaraguru',\n",
       " 'reamma',\n",
       " 'proceducre',\n",
       " 'metacrysis',\n",
       " 'ulhasnagar',\n",
       " 'natalii',\n",
       " 'imstead',\n",
       " 'jtbd',\n",
       " 'punfound',\n",
       " 'ucms',\n",
       " 'rucha',\n",
       " 'hydroquinon',\n",
       " 'aeronotics',\n",
       " 'puneri',\n",
       " 'amaozon',\n",
       " 'october2016',\n",
       " 'assemblylanguage',\n",
       " 'hinsberg',\n",
       " 'dirvert',\n",
       " 'ahmd',\n",
       " 'ehos',\n",
       " '0088882578743',\n",
       " 'laproroscopic',\n",
       " 'adine',\n",
       " 'insideview',\n",
       " 'diasteriomers',\n",
       " 'polae',\n",
       " 'ccnav3',\n",
       " 'blogwriter',\n",
       " 'modline',\n",
       " 'otou',\n",
       " 'fipb',\n",
       " 'volkawagon',\n",
       " 'vvip',\n",
       " 'trolllo',\n",
       " 'pahree',\n",
       " 'iisuperwomanii',\n",
       " 'lekhe',\n",
       " 'lakshmana',\n",
       " 'fndamntl',\n",
       " 'scholardhip',\n",
       " 'vidyarthi',\n",
       " 'dreamspark',\n",
       " 'cadviewer',\n",
       " '6qf',\n",
       " 'bjts',\n",
       " 'caturmasa',\n",
       " 'aricent',\n",
       " 'parrondo',\n",
       " 'f16in',\n",
       " 'annumpackage',\n",
       " 'bombinator',\n",
       " 'terrahawk',\n",
       " 'meht',\n",
       " 'onavo',\n",
       " 'montenegrin',\n",
       " 'univesities',\n",
       " 'wpfw',\n",
       " 'assossiated',\n",
       " 'indiabix',\n",
       " 'tdbhv',\n",
       " 'metropia',\n",
       " 'ge8200',\n",
       " 'sd410',\n",
       " 'unwrinkle',\n",
       " 'lsxmk',\n",
       " 'synapsepay',\n",
       " 'lsxmb',\n",
       " 'lsxma',\n",
       " 'corelcentral',\n",
       " 'devmountain',\n",
       " 'nagpal',\n",
       " 'for40',\n",
       " 'corrispondent',\n",
       " 'pointerpointer',\n",
       " 'susane',\n",
       " 'testcracker',\n",
       " '2ndedition',\n",
       " 'saswata',\n",
       " 'primarina',\n",
       " 'micrel',\n",
       " 'tranversal',\n",
       " 'gratuate',\n",
       " 'aayaa',\n",
       " 'pnkbstra',\n",
       " 'faceflow',\n",
       " 'cloudwatch',\n",
       " 'emroll',\n",
       " 'rieki',\n",
       " 'microbilogy',\n",
       " 'raassttriiy',\n",
       " '3hrt',\n",
       " 'evercare',\n",
       " 'ps80000',\n",
       " 'roopkund',\n",
       " 'homeopathist',\n",
       " 'musah',\n",
       " 'traicionar',\n",
       " '10tail',\n",
       " 'jygalybeg',\n",
       " 'cebinae',\n",
       " 'j80',\n",
       " 'j88',\n",
       " 'saino',\n",
       " 'trinkst',\n",
       " 'havells',\n",
       " 'sbbj',\n",
       " 'walbert',\n",
       " 'oyehappy',\n",
       " 'unwaiveringly',\n",
       " 'homify',\n",
       " 'mustafina',\n",
       " 'kreb',\n",
       " 'kred',\n",
       " 'matanuska',\n",
       " 'suparco',\n",
       " 'beauxbatons',\n",
       " 'sherperd',\n",
       " 'stuthi',\n",
       " 'currunt',\n",
       " 'cof2',\n",
       " 'macdennis',\n",
       " 'globalstar',\n",
       " 'thirdlove',\n",
       " 'urup',\n",
       " 'chakravyuh',\n",
       " 'printerest',\n",
       " 'meyallergy',\n",
       " 'career360',\n",
       " 'bipc',\n",
       " 'flatsigned',\n",
       " 'e243',\n",
       " 'nzt',\n",
       " 'lootenant',\n",
       " 'anthrapology',\n",
       " 'oceaneering',\n",
       " 'sukshm',\n",
       " 'maheshwarah',\n",
       " 'usamerican',\n",
       " 'unella',\n",
       " 'opendtect',\n",
       " 'adchoices',\n",
       " 'buddhafield',\n",
       " 'qainfotech',\n",
       " 'skylux',\n",
       " 'rewardme',\n",
       " 'dfadirectly',\n",
       " '115197',\n",
       " 'varusteleka',\n",
       " 'emean',\n",
       " 'vc707',\n",
       " 'bootfitters',\n",
       " 'wackystudy',\n",
       " 'quickpay',\n",
       " 'pepos',\n",
       " 'csope',\n",
       " 'aadhav',\n",
       " 'transbian',\n",
       " 'nxstage',\n",
       " 'polyarmory',\n",
       " 'apcentral',\n",
       " 'wooplr',\n",
       " 'coderbunnyz',\n",
       " 'ahemedabad',\n",
       " 'guwahti',\n",
       " 'pichkari',\n",
       " 'ltds',\n",
       " 'schwarzchild',\n",
       " 'manveer',\n",
       " 'isecg',\n",
       " 'chronophantasma',\n",
       " 'baywords',\n",
       " 'gnwl',\n",
       " 'nabr',\n",
       " 'mathikere',\n",
       " 'errno2',\n",
       " 'shortfeeds',\n",
       " 'tsute',\n",
       " 'eynos',\n",
       " 'riddhi',\n",
       " 'visveswaraya',\n",
       " 'stoneheart',\n",
       " 'enoent',\n",
       " '1child',\n",
       " 'nayudu',\n",
       " 'gibelline',\n",
       " 'eeru',\n",
       " 'aimim',\n",
       " 'aimil',\n",
       " 'q164',\n",
       " 'q165',\n",
       " 'q160',\n",
       " 'q161',\n",
       " 'maati',\n",
       " 'khux',\n",
       " 'ceqa',\n",
       " 'indrid',\n",
       " 'muthalaithuvam',\n",
       " 'biggboss',\n",
       " 'stottler',\n",
       " 'ddr4',\n",
       " '26wk',\n",
       " 'kfalp',\n",
       " 'bayesians',\n",
       " 'tisco',\n",
       " 'kedia',\n",
       " 'verfify',\n",
       " 'vemo',\n",
       " 'lavietes',\n",
       " 'trotskyism',\n",
       " 'pvm7pro',\n",
       " 'iodimetric',\n",
       " '40vol',\n",
       " 'tichelman',\n",
       " '1company',\n",
       " 'ezerzer',\n",
       " 'shakitmaan',\n",
       " 'saleel',\n",
       " 'ruhrpumpen',\n",
       " 'ayuveda',\n",
       " 'hnlu',\n",
       " 'hadwise',\n",
       " 'cavco',\n",
       " 'devyani',\n",
       " 'lamguages',\n",
       " 'brch2ch2br',\n",
       " 'leanlaunchlab',\n",
       " 'collectorsfrenzy',\n",
       " 'thaam',\n",
       " 'kirchoff',\n",
       " 'engginering',\n",
       " 'living5',\n",
       " 'itbp',\n",
       " 'passneger',\n",
       " 'dailytekk',\n",
       " 'thrime',\n",
       " 'uranius',\n",
       " 'ecclesiasticus',\n",
       " 'phospor',\n",
       " 'amalek',\n",
       " 'na2so4',\n",
       " 'vagional',\n",
       " '8gpa',\n",
       " 'tegmark',\n",
       " 'lowflation',\n",
       " 'magadha',\n",
       " 'standardscaler',\n",
       " 'nareepol',\n",
       " 'e1160',\n",
       " 'parallelzation',\n",
       " 'ajtak',\n",
       " 'eserved',\n",
       " 'wr841',\n",
       " 'bhagvad',\n",
       " 'proraming',\n",
       " 'thisiswhyimbroke',\n",
       " 'lsats',\n",
       " 'nomeniculature',\n",
       " 'admk',\n",
       " 'funfunnykhez',\n",
       " 'niichan',\n",
       " 'kaprekar',\n",
       " 'noyun',\n",
       " '59f',\n",
       " 'jee18',\n",
       " 'jamdani',\n",
       " 'selfman',\n",
       " 'dsox',\n",
       " 'rohingya',\n",
       " 'efficientdynamics',\n",
       " 'mussen',\n",
       " 'webfocus',\n",
       " 'rivo',\n",
       " 'pf3',\n",
       " 'pf5',\n",
       " 'sajakah',\n",
       " 'mahabharatha',\n",
       " 'tanatanbtanctand',\n",
       " '204x106',\n",
       " 'centriod',\n",
       " 'aakrndnn',\n",
       " '3june2016',\n",
       " 'takinng',\n",
       " '17ps',\n",
       " 'scriptilabs',\n",
       " 'ittf',\n",
       " 'rephasement',\n",
       " 'softbricked',\n",
       " 'marivil',\n",
       " 'tantrumxyz',\n",
       " 'choctaws',\n",
       " 'bijjala',\n",
       " 'u0001f3fe',\n",
       " 'p42w10a',\n",
       " 'narandra',\n",
       " 'rs15000',\n",
       " '3lakhs',\n",
       " 'nacirema',\n",
       " 'kgmu',\n",
       " 'counsciousness',\n",
       " 'isound',\n",
       " 'kgmc',\n",
       " 'vaacum',\n",
       " 'marcerator',\n",
       " 'yadavas',\n",
       " 'codeanywhere',\n",
       " 'ioprio',\n",
       " 'gdrive',\n",
       " 'cinamatic',\n",
       " 'basequery',\n",
       " 'webceo',\n",
       " 'brandstory',\n",
       " 'equalism',\n",
       " 'popsticks',\n",
       " 'diyseo',\n",
       " '400709',\n",
       " 'narayna',\n",
       " '10cgpa',\n",
       " 'unproportionate',\n",
       " 'nukber',\n",
       " 'setcontentview',\n",
       " 'mesopotamians',\n",
       " 'commonjs',\n",
       " 'tricyclopropyl',\n",
       " 'profilizer',\n",
       " 'saradha',\n",
       " 'analesys',\n",
       " '120912',\n",
       " 'popurl',\n",
       " 'coldbloodedness',\n",
       " 'vitarra',\n",
       " 'vardayini',\n",
       " 'glomar',\n",
       " 'hcio2',\n",
       " 'iloose',\n",
       " 'putanginamo',\n",
       " 'ladak',\n",
       " 'iiest',\n",
       " 'kyzylorda',\n",
       " 'tostmasters',\n",
       " 'nilekani',\n",
       " 'lerer',\n",
       " 'saudium',\n",
       " 'npci',\n",
       " 'raudra',\n",
       " 'erudites',\n",
       " 'aikibudo',\n",
       " 'futurefuel',\n",
       " 'aayenge',\n",
       " 'unnao',\n",
       " 'coulb',\n",
       " 'pgps',\n",
       " 'songza',\n",
       " 'bottlepotable',\n",
       " 'chronemics',\n",
       " 'racetam',\n",
       " 'selfharmers',\n",
       " 'twitcams',\n",
       " 'clearmy',\n",
       " 'jebasingh',\n",
       " 'schicksal',\n",
       " 'perissodactyla',\n",
       " 'maxivision',\n",
       " 'freelancer97',\n",
       " 'wavecluster',\n",
       " 'fybom',\n",
       " 'adwingate',\n",
       " 'ctvs',\n",
       " 'clithridiate',\n",
       " 'cremonensis',\n",
       " 'dolkun',\n",
       " 'locom2',\n",
       " 'soclose',\n",
       " 'mehanical',\n",
       " 'etip',\n",
       " 'kundanbhag',\n",
       " 'shikshayatan',\n",
       " 'wuhuakeshuo',\n",
       " 'camgemini',\n",
       " 'alphasights',\n",
       " 'testostreone',\n",
       " 'sve14aa12',\n",
       " 'placemens',\n",
       " 'nwebkart',\n",
       " 'kaseorg',\n",
       " 'biomechatronics',\n",
       " 'usd100mil',\n",
       " 'cleganes',\n",
       " 'secondmarket',\n",
       " 'abandanded',\n",
       " 'abbu',\n",
       " 'trezelle',\n",
       " 'jhinjhuriki',\n",
       " 'taxex',\n",
       " 'fewh',\n",
       " 'varunastra',\n",
       " 'csas',\n",
       " 'eagerpanda',\n",
       " 'buggatti',\n",
       " 'yakutat',\n",
       " 'platella',\n",
       " 'movebubble',\n",
       " '000aud',\n",
       " 'quickcreditrepair',\n",
       " 'watchpeopledie',\n",
       " 'icup',\n",
       " 'aminvolved',\n",
       " 'myregistry',\n",
       " 'taccone',\n",
       " 'eharmorny',\n",
       " 'duonase',\n",
       " 'ashanas',\n",
       " 'morarji',\n",
       " 'cartin',\n",
       " 'avegant',\n",
       " '9590907907',\n",
       " 'passoinate',\n",
       " 'sawaro',\n",
       " 'becomewidelypopular',\n",
       " 'ramoji',\n",
       " 'khandan',\n",
       " 'ifcai',\n",
       " 'ishrat',\n",
       " 'akinator',\n",
       " 'sitcore',\n",
       " 'saama',\n",
       " 'cbt1',\n",
       " '9degf',\n",
       " 'intrerview',\n",
       " 'g361h',\n",
       " 'phab',\n",
       " 'gradauation',\n",
       " 'dealschintu',\n",
       " 'jarvise',\n",
       " 'sacudir',\n",
       " 'jaaxy',\n",
       " 'rukmini',\n",
       " 'codingmart',\n",
       " 'ukarine',\n",
       " 'practisc',\n",
       " 'mogule',\n",
       " 'helpwhat',\n",
       " 'thiyya',\n",
       " 'mazumdar',\n",
       " 'd686',\n",
       " 'sahakar',\n",
       " 'yaazha',\n",
       " 'ay503tx',\n",
       " 'mgvcl',\n",
       " 'sftudents',\n",
       " '2qe',\n",
       " 'sheinside',\n",
       " '5o2',\n",
       " 'reflectionless',\n",
       " '75bpm',\n",
       " 'kanele',\n",
       " 'kharar',\n",
       " 'nonfoliated',\n",
       " 'electrolyse',\n",
       " 'sigabrt',\n",
       " 'entrepeneurships',\n",
       " 'codecademy',\n",
       " 'jamanlal',\n",
       " 'a720is',\n",
       " 'chotanagpur',\n",
       " 'endometroperating',\n",
       " '2k16',\n",
       " '2k15',\n",
       " '2k18',\n",
       " 'kamshet',\n",
       " 'eratosthenes',\n",
       " 'ingineering',\n",
       " 'ycmou',\n",
       " 'malinche',\n",
       " 'leasekey',\n",
       " 'emperior',\n",
       " 'covince',\n",
       " '8700p',\n",
       " 'khaleejis',\n",
       " '3320m',\n",
       " '9png',\n",
       " 'iitd',\n",
       " 'pgdast',\n",
       " 'oatmilk',\n",
       " 'banmers',\n",
       " 'nx10',\n",
       " 'methene',\n",
       " 'tapimmune',\n",
       " 'nenycai',\n",
       " 'mclr',\n",
       " 'preterito',\n",
       " 'ps10000',\n",
       " 'skofnung',\n",
       " 'carks',\n",
       " 'giggolo',\n",
       " 'obatampuherbal',\n",
       " 'yeaay',\n",
       " 'hamirpur',\n",
       " 'benckiser',\n",
       " 'jambudvipa',\n",
       " 'katwaria',\n",
       " 'twort',\n",
       " 'dukhrnkrnne',\n",
       " 'byomkesh',\n",
       " 'pigmentatio',\n",
       " '60points',\n",
       " 'blumkin',\n",
       " 'concelling',\n",
       " 'diffrenece',\n",
       " 'shokyu',\n",
       " 'bhupali',\n",
       " 'isperse',\n",
       " ...]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(open(data_home+\"cache/no_embeddings_B.npy\", 'wb'), no_embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training data tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of question1 data (training) tensor: (404290, 35)\n",
      "Shape of question2 data (training) tensor: (404290, 35)\n",
      "Shape of label tensor: (404290,)\n"
     ]
    }
   ],
   "source": [
    "q1_train_data = pad_sequences(question1_word_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "q2_train_data = pad_sequences(question2_word_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "q1_test_data =  pad_sequences(testq1_word_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "q2_test_data = pad_sequences(testq2_word_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "\n",
    "labels = np.array(is_duplicate, dtype=int)\n",
    "print('Shape of question1 data (training) tensor:', q1_train_data.shape)\n",
    "print('Shape of question2 data (training) tensor:', q2_train_data.shape)\n",
    "print('Shape of label tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persist training and configuration data to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(open(data_home+\"cache/\"+Q1_TRAINING_DATA_FILE, 'wb'), q1_train_data)\n",
    "np.save(open(data_home+\"cache/\"+Q2_TRAINING_DATA_FILE, 'wb'), q2_train_data)\n",
    "np.save(open(data_home+\"cache/\"+LABEL_TRAINING_DATA_FILE, 'wb'), labels)\n",
    "np.save(open(data_home+\"cache/\"+WORD_EMBEDDING_MATRIX_FILE, 'wb'), word_embedding_matrix)\n",
    "\n",
    "with open(data_home+\"cache/\"+NB_WORDS_DATA_FILE, 'w') as f:\n",
    "    json.dump({'nb_words': nb_words}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(open(data_home+\"cache/\"+Q1_TESTING_DATA_FILE, 'wb'), q1_test_data)\n",
    "np.save(open(data_home+\"cache/\"+Q2_TESTING_DATA_FILE, 'wb'), q2_test_data)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:qenv]",
   "language": "python",
   "name": "conda-env-qenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
